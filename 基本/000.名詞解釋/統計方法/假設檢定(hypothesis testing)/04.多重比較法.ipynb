{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多重比較法(Multiple-Comparison Procedure)\n",
    "目的 : 若ANOVA分析結果為顯著時，可以用來找出哪幾組和其他組間有顯著差異。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher 最小顯著差異法 (least significant difference, LSD) \n",
    "參考 : 統計學 - 李德治、童惠玲 p616\n",
    "\n",
    "*   優點 : 簡單\n",
    "*   缺點 :\n",
    "    1.  需要進行 $\\tbinom{k}{2}$ 次LSD，所以容易發生型Ｉ誤差。(參考FDR)\n",
    "    2.  若多數組樣本數不相同，則計算速度相對於傳統統計來得慢。\n",
    "\n",
    "此 $H_0 $ 皆為母體平均數相等\n",
    "1.  單一母體平均數之區間估計\\\n",
    "    因為ANOVA過程假設每個小母體的變異數都相等，所以若要估計某個小母體平均數的信賴區間時，須以 MSE 取代母體變異數。\\\n",
    "    單一母體 (第k組) 的 95% 信賴區間 :\\\n",
    "     <font size =5>$ \\bar{x}_k - t_{\\frac{\\alpha}{2},n-k} \\sqrt{\\frac{MSE}{n_k}}\\leq \\mu_k \\leq \\bar{x}_k + t_{\\frac{\\alpha}{2},n-k}\\sqrt{\\frac{MSE}{n_k}}$</font>\n",
    "\n",
    "2.  $\\mu_i - \\mu_j$ 之區間估計\\\n",
    "    因為已知兩獨立母體之平均數差的信賴區間 : \n",
    "    <font size =4>$ (\\bar{x}_1 - \\bar{x}_2) - t_{\\frac{\\alpha}{2},n_1+n_2-2} \\sqrt{\\frac{s_p^2}{n_1}+\\frac{s_p^2}{n_2}}\\leq \\mu_1-\\mu_2 \\leq \n",
    "    (\\bar{x}_1 - \\bar{x}_2) + t_{\\frac{\\alpha}{2},n_1+n_2-2}\\sqrt{\\frac{s_p^2}{n_1}+\\frac{s_p^2}{n_2}}$</font>\n",
    "    \n",
    "    所以把樣本變異數 $s_p^2$ 修改為MSE即可 : \\\n",
    "    <font size =5>$ (\\bar{x}_i - \\bar{x}_j) - t_{\\frac{\\alpha}{2},n-k} \\sqrt{\\frac{MSE}{n_i}+\\frac{MSE}{n_j}}\\leq \\mu_i-\\mu_j \\leq \n",
    "    (\\bar{x}_i - \\bar{x}_j) + t_{\\frac{\\alpha}{2},n-k} \\sqrt{\\frac{MSE}{n_i}+\\frac{MSE}{n_j}}$</font>\n",
    "    \n",
    "3.  LSD \\\n",
    "    由(2)可得<font size =4>$t^* = \\frac{(\\bar{x}_i - \\bar{x}_j)}{\\sqrt{\\frac{MSE}{n_i}+\\frac{MSE}{n_j}}}$</font> ，所以當$|t^*| > t_{\\frac{\\alpha}{2},n-k}$ (信賴區間不包含$H_0$) 時，拒絕虛無假設(reject $H_0$)。\n",
    "    \n",
    "    可以改寫成 : 當$  |\\bar{x}_i - \\bar{x}_j| > t_{\\frac{\\alpha}{2},n-k} \\sqrt{\\frac{MSE}{n_i}+\\frac{MSE}{n_j}}$ 時，拒絕虛無假設(reject $H_0$)。\n",
    "    \n",
    "    而此定義LSD為 :\\\n",
    "    <font color = red>$LSD = t_{\\frac{\\alpha}{2},n-k} \\sqrt{\\frac{MSE}{n_i}+\\frac{MSE}{n_j}} $</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 聯合信賴區間(simultaneous confidence intervals)\n",
    "為了解決 LSD 進行多重檢定出現全體型I錯誤 (overall type I error) 的問題，調整各信賴區間對的機率相當於 $1-\\alpha$ ，而調整後的信賴區間就稱為聯合信賴區間。\n",
    "\n",
    "以下為聯合信賴區間檢定法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bonferroni 多重比較法\n",
    "*   摘要 : \n",
    "\n",
    "    假設型I錯誤發生機率為$\\alpha$，若有 k 個小母體，需檢定 $m = C^k_2$ 次。\\\n",
    "    Bonferroni 認為此會<font color = red> 造成型 I 錯誤的累積，使得型I錯誤膨脹成 $m\\alpha$ ，所以必須將顯著水準改為 $\\frac{\\alpha}{m}$</font>。\n",
    "\n",
    "依照 Bonferroni ，$m = C^k_2$ 個母體平均數差的 $1-\\alpha$ 聯合信賴區間為 : \\\n",
    "    <font size =5>$ (\\bar{x}_i - \\bar{x}_j) - t_{\\frac{\\alpha}{2m},n-k} \\sqrt{\\frac{MSE}{n_i}+\\frac{MSE}{n_j}}\\leq \\mu_i-\\mu_j \\leq \n",
    "    (\\bar{x}_i - \\bar{x}_j) + t_{\\frac{\\alpha}{2m},n-k} \\sqrt{\\frac{MSE}{n_i}+\\frac{MSE}{n_j}}$</font>\n",
    "\n",
    "虛無假設為 : $H_0 : \\mu_i = \\mu_j$\n",
    "1.  若 $\\mu_1-\\mu_2$ 之聯合信賴區間包含 0，則不拒絕虛無假設。\n",
    "2.  若 $\\mu_1-\\mu_2$ 之聯合信賴區間皆為負值，則表示 $\\mu_i < \\mu_j$。\n",
    "3.  若 $\\mu_1-\\mu_2$ 之聯合信賴區間皆為正值，則表示 $\\mu_i > \\mu_j$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scheffe 多重比較法\n",
    "*   摘要 :\n",
    "\n",
    "    把傳統信賴區間法中的 $t$ 分配改用 $F$ 分配 (因為 $t_{\\frac{\\alpha}{2},n} = \\sqrt{F_{\\alpha,1,n}}$)。為了避免顯著水準膨脹，因此在 $F$ 值前增加調整係數 $(k-1)$，使得信賴區間加大縮小型I錯誤。\n",
    "\n",
    "依照 Scheffe ， k 個小母體的母體平均數差之 $1-\\alpha$ 聯合信賴區間為 : \\\n",
    "    <font size =4>$ (\\bar{x}_i - \\bar{x}_j) - \\sqrt{(k-1)F_{\\alpha,k-1,n-k}} \\sqrt{\\frac{MSE}{n_i}+\\frac{MSE}{n_j}}\\leq \\mu_i-\\mu_j \\leq \n",
    "    (\\bar{x}_i - \\bar{x}_j) + \\sqrt{(k-1)F_{\\alpha,k-1,n-k}} \\sqrt{\\frac{MSE}{n_i}+\\frac{MSE}{n_j}}$</font>\n",
    "\n",
    "*   缺點 :\n",
    "\n",
    "    因 Scheffe 過於保守，雖然使得 type I error 機率降低，但卻造成型 II 錯誤的發生機率上生，導致檢定力減弱。此方法比較適用於非成對處理之檢定，例如虛無假設為：$H_0 = c_1\\mu_1+c_2\\mu_2+...+c_k\\mu_k = 0$。\n",
    "\n",
    "虛無假設為 : $H_0 : \\mu_i = \\mu_j$\n",
    "1.  若 $\\mu_1-\\mu_2$ 之聯合信賴區間包含 0，則不拒絕虛無假設。\n",
    "2.  若 $\\mu_1-\\mu_2$ 之聯合信賴區間皆為負值，則表示 $\\mu_i < \\mu_j$。\n",
    "3.  若 $\\mu_1-\\mu_2$ 之聯合信賴區間皆為正值，則表示 $\\mu_i > \\mu_j$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tukey 公正顯著差異法 (Tukey honest significant difference, HSD), 或稱 Tukey's T 法\n",
    "\n",
    "*   摘要 :\n",
    "\n",
    "    和 LSD 類似，但是 HSD 使用的並非 t dis. 而是 t 的全距分配 $q_{\\alpha,k,n-k}$ (studentized range distribution)。\n",
    "\n",
    "*   t 全距分配 :\n",
    "\n",
    "    假設 $x_1,x_2,...,x_k \\stackrel{i.i.d}{\\sim} N(\\mu,\\sigma^2)$，則 t 的全距分配為 : $q_{k,n-k} = \\frac{R}{s}$ ， 其中 $R = \\max\\limits_{i} x_i - \\min\\limits_{i} x_i$，$s$ 為樣本標準差，k、n-k 為自由度。\n",
    "\n",
    "*   缺點 :\n",
    "\n",
    "    <font color = red>必須在各組樣本數相同時才可以進行檢定</font>。\n",
    "\n",
    "依照 HSD 多重比較法 ， k 個小母體的母體平均數差之 $1-\\alpha$ 聯合信賴區間為 :\\\n",
    "    <font size =4>$ (\\bar{x}_i - \\bar{x}_j) - q_{\\alpha,k,n-k} \\sqrt{\\frac{MSE}{n}+\\frac{MSE}{n}}\\leq \\mu_i-\\mu_j \\leq \n",
    "    (\\bar{x}_i - \\bar{x}_j) + q_{\\alpha,k,n-k} \\sqrt{\\frac{MSE}{n}+\\frac{MSE}{n}}$</font>\n",
    "\n",
    "在虛無假設 $H_0 = \\mu_i = \\mu_j $  成立的情況下，不等式可以改成 $|\\bar{x}_i - \\bar{x}_j| > q_{\\alpha,k,n-k} \\sqrt{\\frac{MSE}{n}+\\frac{MSE}{n}}$。\\\n",
    "令 $HSD = q_{\\alpha,k,n-k} \\sqrt{\\frac{MSE}{n}+\\frac{MSE}{n}} $ ，則決策法則變成 : 若 $|\\bar{x}_i - \\bar{x}_j| > HSD $，則拒絕虛無假設。\n",
    "\n",
    "決策結果 : \n",
    "1.  若 $\\mu_1-\\mu_2$ 之聯合信賴區間包含 0，則不拒絕虛無假設。\n",
    "2.  若 $\\mu_1-\\mu_2$ 之聯合信賴區間皆為負值，則表示 $\\mu_i < \\mu_j$。\n",
    "3.  若 $\\mu_1-\\mu_2$ 之聯合信賴區間皆為正值，則表示 $\\mu_i > \\mu_j$。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tukey-Karamer 檢定程序\n",
    "*   摘要 :\n",
    "\n",
    "    改良 HSD 法，使它不受樣本數需相同的限制。此方法將 $HSD$ 法的 $q_{\\alpha,k,n-k}$ 改為 $\\frac{q_{\\alpha,k,n-k}}{\\sqrt{2}}$。\n",
    "\n",
    "$1-\\alpha$ 信賴區間 : \\\n",
    "    <font size =4>$ (\\bar{x}_i - \\bar{x}_j) - \\frac{q_{\\alpha,k,n-k}}{\\sqrt{2}} \\sqrt{\\frac{MSE}{n_i}+\\frac{MSE}{n_j}}\\leq \\mu_i-\\mu_j \\leq \n",
    "    (\\bar{x}_i - \\bar{x}_j) +\\frac{q_{\\alpha,k,n-k}}{\\sqrt{2}} \\sqrt{\\frac{MSE}{n_i}+\\frac{MSE}{n_j}}$</font>\n",
    "\n",
    "令 $\\omega = \\frac{q_{\\alpha,k,n-k}}{\\sqrt{2}}$，則決策法則變為 : 若 $|\\bar{x}_i - \\bar{x}_j| > \\omega $，則拒絕虛無假設。\n",
    "\n",
    "決策結果 : \n",
    "1.  若 $\\mu_1-\\mu_2$ 之聯合信賴區間包含 0，則不拒絕虛無假設。\n",
    "2.  若 $\\mu_1-\\mu_2$ 之聯合信賴區間皆為負值，則表示 $\\mu_i < \\mu_j$。\n",
    "3.  若 $\\mu_1-\\mu_2$ 之聯合信賴區間皆為正值，則表示 $\\mu_i > \\mu_j$。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 其他\n",
    "待補 : \n",
    "*   Newman – Keuls法 : Newman- Keuls法與Tukey法非常相似，但是Newman- Keuls法對於每一個比較可以都有各自的α值。此方法因此可以執行更多的比對，因此其檢定力比Tukey法更強大。\n",
    "[參考網址2](https://en.wikipedia.org/wiki/Newman%E2%80%93Keuls_method)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4206480afc6f8f20a91f9b30d4e9d2907612993729e8a589e2c16a111e42b69c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
