{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   簡單線性迴歸 \n",
    "*   只有一個自變數(x)和一個依變數(y)的情形\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   多元迴歸(Multiple regression)，或稱一般線性回歸\n",
    "*   大於一個自變數(x1,x2,...)的情形。例如 $ y = \\beta_0 + \\beta_1 x_1 + \\beta_1 x_2+ \\epsilon $ 。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###   多項式的回歸模型 (Polynomial regression)\n",
    "*   為非線性回歸，自變數有次方項的情形。例如 $ y = \\beta_0 + \\beta_1 x + \\beta_1 x^2+ \\epsilon $ 。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 兩種求解方法\n",
    "線性模型最常見的解法有兩種，分別為 Closed-form (閉式解) 與梯度下降 (Gradient descent)。當特徵少時使用 Closed-form 較為適合，使用下面公式來求出 θ 值。我們又可以說線性模型的最小平方法的解即為 Closed-form。\n",
    "\n",
    "$\\qquad \\theta = (X^TX)^{-1}X^Ty$\n",
    "\n",
    "若當是複雜的問題時 Gradient descen 較能解決，其原因是大部分的問題其實是沒有公式解的。我們只能求出一個函數 f(x) 使其誤差最小越好。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4206480afc6f8f20a91f9b30d4e9d2907612993729e8a589e2c16a111e42b69c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
