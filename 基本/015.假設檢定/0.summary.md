
# 01.t-test

t-test 常作為檢定<font color = red>一群來自常態分配母體</font>的<font color = red>獨立樣本之期望值是否為某一實數</font>，或是二（兩）群<font color = red>來自常態分配母體</font>的<font color = red>獨立樣本之期望值的差是否為某一實數</font>。

<font color = red>注意</font> : 常態為必要條件，通常會搭配 KS-test 去檢定是否為常態。

<br>

---

# 02.FDR

## 定義
是統計學中常見的一個名詞，翻譯爲僞發現率，其意義爲是 <font color = red> 錯誤拒絕（拒絕真的（原）假設）的個數佔所有被拒絕的原假設個數的比例的期望值</font>。

FDR是個<font color = red>期望值</font>

## 目的 : 解決多重檢定問題
*   多重檢定問題 : 進行多個檢定, 使得發生型一錯誤的機率增加

## 解決多重檢定問題
1.  更改 $\alpha$值
2.  修正 p_value

<br>

---

#   03.ANOVA


##  目的
    檢定其各類別間平均數是否相等

<font size = 3 color = orange >迴歸分析的 ANOVA 表和此不同，參考 "監督式學習-> Regression-> Multiple regression"。</font>

## 前提假設
*   自變數(又稱解釋變數、獨立變數)為類別變數(categorical variable)
*   依變數(又稱應變數、因變數)必須是連續變數(continuous variable)
*   <font color = red>母群體必須是常態分佈(Normal Distribution)</font>
*   獨立事件(Independent event)：樣本須為獨立變項(Independent variable)
*   變異數(Variance)同質性：<font color = red>樣本間的變異數必須相等。</font>


##  因子
因子指的是分類性（例如班級、血型等），根據因子，ANOVA分為：
*   單因子變異數分析(One-way ANOVA)：只有一個自變項的變異數分析。
    *   檢定各因子類別的平均是否相等
*   雙因子變異數分析 (two way ANOVA)
    1.  非重複試驗  :   檢定各因子類別的平均是否相等
    2.  重複試驗 : 也要檢定因子間是否有交互作用

<br>

---

#   04.多重比較法

##  目的
    若 ANOVA 分析結果為顯著時(即存在因子類別的平均數不相等)，可以用來找出哪幾組和其他組間有顯著差異。

##  方法
*   Fisher 最小顯著差異法 (least significant difference, LSD) 
*   聯合信賴區間(simultaneous confidence intervals)
    *   Bonferroni 多重比較法
    *   Scheffe 多重比較法
    *   Tukey 公正顯著差異法 (Tukey honest significant difference, HSD), 或稱 Tukey's T 法
    *   Tukey-Karamer 檢定程序

### Fisher 最小顯著差異法 (least significant difference, LSD) 

*   優點 : 簡單
*   缺點 :
    1.  需要進行 $\tbinom{k}{2}$ 次LSD，所以容易發生型Ｉ誤差。(參考FDR)
    2.  若多數組樣本數不相同，則計算速度相對於傳統統計來得慢。


### Bonferroni 多重比較法

*   假設型I錯誤發生機率為$\alpha$，若有 k 個小母體，需檢定 $m = C^k_2$ 次。\
    Bonferroni 認為此會<font color = red> 造成型 I 錯誤的累積，使得型I錯誤膨脹成</font> $m\alpha$ <font color = red>，所以必須將顯著水準改為</font> $\frac{\alpha}{m}$。


### Scheffe 多重比較法
*   把傳統信賴區間法中的 $t$ 分配改用 $F$ 分配 (因為 $t_{\frac{\alpha}{2},n} = \sqrt{F_{\alpha,1,n}}$)。為了避免顯著水準膨脹，因此在 $F$ 值前增加調整係數 $(k-1)$，使得信賴區間加大縮小型I錯誤。


### Tukey 公正顯著差異法 (Tukey honest significant difference, HSD), 或稱 Tukey's T 法
*   和 LSD 類似，但是 HSD 使用的並非 t dis. 而是 t 的全距分配 $q_{\alpha,k,n-k}$ (studentized range distribution)。
*   缺點 :  <font color = red>必須在各組樣本數相同時才可以進行檢定</font>。


### Tukey-Karamer 檢定程序
*   改良 HSD 法，使它不受樣本數需相同的限制。此方法將 $HSD$ 法的 $q_{\alpha,k,n-k}$ 改為 $\frac{q_{\alpha,k,n-k}}{\sqrt{2}}$。

<br>

---

#   卡方檢定 (Chi-Squared Test)

常用於以下三種檢定:
1.  Goodness of Fit Test (適合度檢定) : 樣本與母體分布是否相似。(不同咖啡喜好度是否一樣)
2.  Tests of Independence (獨立性檢定) : 各類別是否獨立。(男女和科系是否相關)
3.  Tests of Homogeneity(齊一性檢定) : 檢定兩個或兩個以上不同的母體是否具有相同的分配或相同的比例。(不同店家的滿意度比例是否相同)

<br>

不管哪個檢定都包含三個步驟：
1.  計算卡方檢定的統計值「 $\chi ^{2}$ 」：把每一個觀察值和理論值的差做平方後、除以理論值、再加總。
2.  計算  $\chi ^{2}$ 統計值的自由度「$df$」。
3.  依據研究者設定的信心水準（顯著性水平、P值或對應$\alpha$值），查出自由度為 $df$ 的卡方分配臨界值，比較它與第1步驟得出的 $\chi ^{2}$ 統計值，推論能否拒絕虛無假說。

<br>

## 基本假設

### Goodness of Fit Test (適合度檢定)
1.  互斥的類別 : 每一位研究參與者或每一個觀察只能被分配到一個類別，必須避免同一位參與者或同一個觀察被多次計算。
2.  彼此獨立的觀察 : 一位研究參與者或一個觀察被分配到一個類別不會對其他的類別帶來影響，也就是說，分配到任一類別的標準是相同的 ( 機率不會因為其他類別改變 )。
3.  足夠的樣本數 : 一般而言，卡方檢定要求每一個類別的期望次數不得少於5。如果期望次數太小，卡方檢定可能會產生錯誤的結果。

### Tests of Independence (獨立性檢定)
1.  類別之間互斥且獨立 : 列聯表中的兩個變項所構成的類別之間必須互斥且獨立，換句話說每個觀察值只能被分到一個類別 (不可重複計算)。
2.  資料須為次數 : 列聯表中的每個儲存格裡的資料須為次數，而不是其他類型的數值。雖然卡方獨立性檢定經常用在名義尺度的變項資料上，但這不代表次序、等距或比率尺度的變項資料無法使用，只要將其他測量尺度的變項資料重新編碼成互斥的類別、資料轉換成次數，即可使用卡方獨立性檢定。
3.  足夠的樣本數 : 理論上卡方檢定要求列聯表中每個儲存格裡的期望次數不得少於5，若違反這個假設，卡方檢定可能會產生錯誤的結果。

<br>

---

#   Fisher’s Exact Test (費雪爾正確概率檢定)
    若單元格的期望次數小於5，則使用卡方效果不佳，此時會採用 Fisher's Exact Test。

<font color =red size = 5 >目的 : 分析兩組數據是否顯著相關</font>

<br>

---

#   RR,OR

## Relative Risk (相對危險性,RR)
    相對環境對於感興趣的事件發生率的比率

## Attributable Risk (可歸因風險, AR):又稱 rate difference(率差),excess risk(超額危險度)
    相對環境對於事件發生率的變化量 (差的絕對值)

## odds(勝算)
    事件發生率相較不發生率的比值(事件發生比率 / 事件不發生比率 = 事件發生數/事件未發生數)

## odds ratio (勝算比, OR)
    用於表示環境與事件的關聯性之指標，以勝算的比例來表示不同環境下有無發病比率的倍率(暴露組的OR/為暴露組的OR)