{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "參考資料 : https://github.com/andy6804tw/2021-13th-ironman/tree/main/4.%E5%92%B1%E5%80%91%E4%B8%80%E8%B5%B7%E5%81%9A%E8%B3%87%E6%96%99%E6%B8%85%E7%90%86%E5%92%8C%E5%89%8D%E8%99%95%E7%90%86"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 前言\n",
    "很多演算法對數據範圍非常的敏感。因此為了要讓模型訓練的更強大，通常的做法是對特徵進行調節，使得數據更適合這些演算法。一般來說，我們在做機器學習時往往會做特徵的正規化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 載入相關套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # 繪圖套件\n",
    "import seaborn as sns # 以 matplotlib 為底層的高階繪圖套件\n",
    "from sklearn.datasets import load_iris # data\n",
    "\n",
    "np.set_printoptions(suppress=True)  # 全域設定, 限制陣列列印元素方式或數量,此為是否抑制顯示小數位, 參考\"基本指令\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 載入資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0              5.1           3.5            1.4           0.2      0.0\n",
       "1              4.9           3.0            1.4           0.2      0.0\n",
       "2              4.7           3.2            1.3           0.2      0.0\n",
       "3              4.6           3.1            1.5           0.2      0.0\n",
       "4              5.0           3.6            1.4           0.2      0.0\n",
       "..             ...           ...            ...           ...      ...\n",
       "145            6.7           3.0            5.2           2.3      2.0\n",
       "146            6.3           2.5            5.0           1.9      2.0\n",
       "147            6.5           3.0            5.2           2.0      2.0\n",
       "148            6.2           3.4            5.4           2.3      2.0\n",
       "149            5.9           3.0            5.1           1.8      2.0\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "df_data = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= ['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm','Species'])\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 檢查缺失值\n",
    "使用 numpy 所提供的函式來檢查是否有 NA 缺失值，假設有缺失值使用 dropna() 來移除。使用的時機在於當只有少量的缺失值適用，若遇到有大量缺失值的情況，或是本身的資料量就很少的情況下建議可以透過機器學習的方法補值來預測缺失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked missing data(raw data): 1\n",
      "delete missing data\n",
      "checked missing data(NAN mount): 0\n"
     ]
    }
   ],
   "source": [
    "print(\"checked missing data(raw data):\",len(np.where(np.isnan(df_data['Species']))))\n",
    "X = df_data.drop(labels=['Species'],axis=1).values # 移除Species並取得剩下欄位資料\n",
    "y = df_data['Species']\n",
    "# checked missing data\n",
    "print(\"delete missing data\")\n",
    "print(\"checked missing data(NAN mount):\",len(np.where(np.isnan(X))[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 切割訓練集與測試集\n",
    "我們透過 Sklearn 所提供的 train_test_split() 方法來為我們的資料進行訓練集與測試集的切割。在此方法中我們可以設定一些參數來讓我們切割的資料更多樣性。其中 test_size 參數就是設定測試集的比例。\\\n",
    "另外預設資料切割的方式是隨機切割 shuffle=True 對原始數據進行隨機抽樣，以保證隨機性。若想要每次程式執行時切割結果都是一樣的可以設定亂數隨機種子 random_state 並給予一個隨機數值。\\\n",
    "最後一個是 stratify 分層隨機抽樣，特別是在原始數據中樣本標籤分佈不均衡時非常有用。使用時機是確保分類問題 y 的類別數量分佈要與原資料集一致。以免資料集切割不平均導致模型訓練時有很大的偏差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (105, 4)\n",
      "test shape: (45, 4)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print('train shape:', X_train.shape)\n",
    "print('test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardization平均&變異數標準化\n",
    "將所有特徵標準化，也就是高斯分佈。使得數據的平均值為 0，方差為 1。適合的使用時機於當有些特徵的方差過大時，使用標準化能夠有效地讓模型快速收斂。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料集 X 的平均值 :  [5.87333333 3.0552381  3.7847619  1.20571429]\n",
      "資料集 X 的標準差 :  [0.85882164 0.45502087 1.77553646 0.77383751]\n",
      "\n",
      "StandardScaler 縮放過後訓練集的平均值 :  [ 0. -0. -0. -0.]\n",
      "StandardScaler 縮放過後訓練集的標準差 :  [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# scaled之後的資料零均值，單位方差  \n",
    "print('資料集 X 的平均值 : ', X_train.mean(axis=0))\n",
    "print('資料集 X 的標準差 : ', X_train.std(axis=0))\n",
    "\n",
    "print('\\nStandardScaler 縮放過後訓練集的平均值 : ', X_train_scaled.mean(axis=0))\n",
    "print('StandardScaler 縮放過後訓練集的標準差 : ', X_train_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "訓練集的 Scaler 擬合完成後，我們就能做相同的轉換在測試集上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler 縮放過後測試集的平均值 :  [-0.11643861  0.01534903 -0.05024191 -0.02748619]\n",
      "StandardScaler 縮放過後測試集的標準差 :  [0.85754489 0.83947065 0.96847064 0.9374037 ]\n"
     ]
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('\\nStandardScaler 縮放過後測試集的平均值 : ', X_test_scaled.mean(axis=0))\n",
    "print('StandardScaler 縮放過後測試集的標準差 : ', X_test_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想將轉換後的資料還原可以使用 inverse_transform() 將數值還原成原本的輸入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料 : \n",
      " [[7.3 2.9 6.3 1.8]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.3 2.8 5.1 1.5]]\n",
      "標準化再還原後 : \n",
      " [[7.3 2.9 6.3 1.8]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [6.3 2.8 5.1 1.5]]\n"
     ]
    }
   ],
   "source": [
    "# 將縮放的資料還原\n",
    "X_test_inverse = scaler.inverse_transform(X_test_scaled)\n",
    "print(\"原始資料 : \\n\",X_test[:3])\n",
    "print(\"標準化再還原後 : \\n\",X_test_inverse[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMaxScaler最小最大值標準化\n",
    "在 MinMaxScaler 中是給定了一個明確的最大值與最小值。每個特徵中的最小值變成了0，最大值變成了1。數據會縮放到到[0,1]之間。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "資料集 X 的最小值 :  [4.3 2.  1.1 0.1]\n",
      "資料集 X 的最大值 :  [7.9 4.4 6.9 2.5]\n",
      "\n",
      "StandardScaler 縮放過後訓練集的最小值 :  [0. 0. 0. 0.]\n",
      "StandardScaler 縮放過後訓練集的最大值 :  [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# scaled 之後的資料最小值、最大值  \n",
    "print('資料集 X 的最小值 : ', X_train.min(axis=0))\n",
    "print('資料集 X 的最大值 : ', X_train.max(axis=0))\n",
    "\n",
    "print('\\nStandardScaler 縮放過後訓練集的最小值 : ', X_train_scaled.min(axis=0))\n",
    "print('StandardScaler 縮放過後訓練集的最大值 : ', X_train_scaled.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler 縮放過後測試集的最小值 :  [ 0.02777778  0.125      -0.01724138  0.04166667]\n",
      "StandardScaler 縮放過後測試集的最大值 :  [0.83333333 0.83333333 0.89655172 0.95833333]\n"
     ]
    }
   ],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print('\\nStandardScaler 縮放過後測試集的最小值 : ', X_test_scaled.min(axis=0))\n",
    "print('StandardScaler 縮放過後測試集的最大值 : ', X_test_scaled.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MaxAbsScaler絕對值最大標準化\n",
    "MaxAbsScaler 與 MinMaxScaler 類似，所有數據都會除以該列絕對值後的最大值。 數據會縮放到到[-1,1]之間。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler 縮放過後測試集的最小值 :  [0.5443038  0.45454545 0.14492754 0.04      ]\n",
      "StandardScaler 縮放過後測試集的最大值 :  [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "scaler = MaxAbsScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "print('\\nStandardScaler 縮放過後測試集的最小值 : ', X_scaled.min(axis=0))\n",
    "print('StandardScaler 縮放過後測試集的最大值 : ', X_scaled.max(axis=0)) #因為data 都 >0, 所以只會顯示1,如果有<0的資料且絕對值後是最大的, 則會出現-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RobustScaler\n",
    "可以有效的縮放帶有outlier的數據，透過Robust如果數據中含有異常值在縮放中會捨去。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "StandardScaler 縮放過後測試集的最小值 :  [-1.15384615 -2.         -0.95714286 -0.8       ]\n",
      "StandardScaler 縮放過後測試集的最大值 :  [1.61538462 2.8        0.72857143 0.8       ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "print('\\nStandardScaler 縮放過後測試集的最小值 : ', X_scaled.min(axis=0))\n",
    "print('StandardScaler 縮放過後測試集的最大值 : ', X_scaled.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = scaler.transform(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4206480afc6f8f20a91f9b30d4e9d2907612993729e8a589e2c16a111e42b69c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
