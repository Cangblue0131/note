<!-- markdownlint-disable MD033 -->
<!-- markdownlint-disable MD010 -->
<!-- markdownlint-disable MD037 -->
<!-- markdownlint-disable MD041 -->

[學習網址](https://www.youtube.com/watch?v=qgef6G9rzts&list=PLTp0eSi9MdkNZB4kyLSzIXIUy9JQOJ5AM)

<font size = 4 color = orange>備註 : 不一定會寫上所有公式.</font>

# L1

* 獲取資料時, 可先用長條圖或盒鬚圖等圖形, 以視覺化的方式檢視. 以便規劃後續研究方式.
* 相關係數($\frac{cov(X,Y)}{(\sigma(X)\sigma(Y))}$)為零代表"無線性關係", 不代表沒關係.
* 想了解兩變數期望上如何影響, 可以使用條件期望值的形式(E(Y|X))

# L2 Simple Linear Regression

Data : ${(Y_i, X_i)}$; Aim : $E(Y|X) = f(X)$.

* 目的為了解在不同X的特定狀況下對應的Y之平均行為. 因為在X為某值時, Y同樣為隨機變數, 所以回歸所估計出來的值是期望值. 其中 $E(Y|X)$ 為X的函數.
* 呈現變數間的相關性最簡單的圖形是"散佈圖"
* 使用圖形呈現資料有助於決定使用的估計模型.
* 簡單線性回歸 : $Y = E(Y|X)+\epsilon$, $\epsilon$為誤差, 用於表示模型與資料間的誤差. 其中$E(Y|X) = \beta_0 + \beta_1X$.
* $\epsilon \sim N(0, \sigma^2)$, 其中 $\sigma$ 和 X 無關(不會受到 X 影響), 對於此模型, 假設在各個位置上 $\sigma$ 皆相同<font size = 3 color = red>(此假設不一定正確)</font>.
* 由上可知, 需要估計的參數為 : $(\beta_0, \beta_1, \sigma)$

對於離散型X, 由 $E(Y|X)$可知, 各X值估計的結果為該X值下Y的平均值. 並且在變數間的相關性很單調時(沒有其他影響因素), 當資料量很大時, 繪製的回歸線也會在各X值下經過 $E(Y|X)$.

![L2-1](figure\L2-1.PNG)

![L2-2](figure\L2-2.PNG)

* 簡單線性回歸之符號解釋
  * $\beta_0$ : 截距
  * $\beta_1$ : 斜率, 每增加一單位, 平均增加$\beta_1$.
  * $\epsilon$ : 在特定X位置之結果與平均結果差異的分佈狀況, 常用推測為常態.
  * $\sigma$ : 描述資料不能解釋的部分.

* $\sigma$ 出現(增加)原因
  1. 量測誤差
  2. 重要解釋變數沒收集到(沒放入回歸中). 例如身高體重對於男女, 如下圖1.
  3. 模型的選擇錯誤, 如下圖2.

基本上 1 和 2 不能解決.

![L2-3](figure\L2-3.PNG)
![L2-4](figure\L2-4.PNG)

# L3 Least Squares Estimate

估計的準則 : 找一個好的觀測和估計差異越小越好. $\sum(Y_i - (\beta_0 + \beta_1X_i))^2$, 也就是最小平方法(Least squares estimate, LSE).

* 估計得到的參數會以$\hat{\beta}$表示, 求得方法為針對 LSE 進行微分.
* $\hat{\beta_0} = \bar{Y} - \hat{\beta_1}\bar{X}$
* $\hat{\beta_1} = \frac{S_{XY}}{S_{XX}}$
* $S_{XY} = \sum{(X_i-\bar{X})^2}$
* 相關係數的正負理論上要和 $\beta_1$ 相同, 並且是正比於$\hat{\beta_1}$. 其中差異為 $Cov(X,Y) = \frac{S_{XY}}{|S_X||S_Y|} =  \frac{S_{XY}}{S_{XX}}\sqrt{\frac{S_{XX}}{S_{YY}}} = \hat{\beta_1}\sqrt{\frac{S_{XX}}{S_{YY}}}$

求得參數後, 可更深入探討

1. 估計 mean response
2. 預測資料
3. 檢定參數 : $H_0 : \beta_1 = \hat{\beta_1}$

## 估計 $\sigma^2$

因 $Y = E[Y|X] + \epsilon$, 且$\epsilon \sim N(0, \sigma^2)$.

所以 $\epsilon = Y - E[Y|X]$, 假設 E[Y|X] 由模型估計, 可估計 $\epsilon$ 為 $e_i = Y - \hat{Y}$.

$e_i$ 又稱為 residual(殘差), 是用來估計 $\epsilon$(誤差) 的. 可解釋為觀測與期望(估計)的差距.

最後可得 $\hat{\sigma^2} = \frac{1}{n-2}\sum(e - E(e))^2 = \frac{1}{n-2}\sum{e^2}$. 這裡為了不偏, 所以除以(n-2). 簡單來說就是因為為了 $\sigma$ , 已經先去估計兩個 $\beta$, 所以自由度-2. <font size = 3 color = red>此講法只適合用來記憶, 不是正確解釋.</font>

依此類推, 可以改成 $\hat{\sigma^2} = \frac{1}{n-(p+1)}\sum{e^2}$, 其中 p 為解釋變數數量.
