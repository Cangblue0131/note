<!-- markdownlint-disable MD033 -->
<!-- markdownlint-disable MD010 -->
<!-- markdownlint-disable MD037 -->
<!-- markdownlint-disable MD041 -->
<!-- markdownlint-disable MD024 -->

補 :

關於 mean response 和 預測 的差異可以去聽這段 : [L14](https://youtu.be/8Qzqf51O6ZE?si=2OPhPTORPz05FFLA&t=1308) 

# L12 Generalized Linear Model

從此開始 Y 可能是離散型資料, 例如 Y = {0,1} 或 count data : {0, 1, 2, ...}

過去目標是得到 $Y = E[Y|X] + \epsilon$, 其中 $E[Y|X] = \beta_0 + \beta^TX$, $Y \sim N(E[Y|X], \sigma^2)$. 不過若 Y 為離散型, 則此結果會很奇怪.

當 Y 為 {0, 1} 時, $E[Y|X] = P(Y=1|X) \in [0, 1]$; 當 Y 為 {0, 1, ....}時, $E[Y|X]$ 也 $\in [0, 1]$

## 此時會用到的分佈

### Bernoulli

$Y~\sim Ber(p)$ with $p = P(Y=1)$.

* $f(y) = p^y(1-p)^{(1-y)},~ y = 0, 1$
* $E(Y) = p$
* $Var(Y) = p(1-p)$, 所以 p = 0.5 時變異最大.

### Poission

$Y \sim Poi(\lambda)$

* $f(y) = \frac{e^{-\lambda}\lambda^y}{y!}$
* $E(Y) = \lambda$
* $Var(Y) = \lambda$

## Estimation of parameter

由 $Y_i \sim(iid) Ber(p)$ 來說

### likehood function

從假設給定 p, 求得 "看到目前資料的機率去推論" 最有可能的p.

看到目前資料的機率 $Y_i \to f_p(Y_i)$, 所以看到整組資料的機率為 $\prod f_p(Y_i) = L(p)$.

其值可畫出圖形類似如下:

![L12-1](figure\L12-1.PNG)

最高點代表是 該p的情況下 此資料最有可能出現, 找這點的估計方法稱為 MLE(最大概似估計, maximum likelihood estimation).

從式子可知道, $L(p) = \prod(p^{Y_i}(1-p)^{(1-Y_i)})$. 使用 log 和 微分最後推得出 $\hat{p} = \frac{1}{n}\sum Y_i$

## Inference rocedure

Model : $Y \sim f_\theta(y)$

Data : ${Y_i}$

Aim : estimate $\theta$ $\to$ 使用 MLE 估計.

# L13 Generalized Linear Model (2)

## Logistic Regression

* Binary response $Y \in \{0, 1\}$
* covariates : $X = (X_1, ..., X_p)$
* target : $E[Y|X] = P(Y=1|X) = P_x$

### Modeling

1. $Y|X \sim Bernoulli(P_x)$
2. $g(P_x) = \beta + \beta^TX$, g 稱為連結函數, 用來連結條件機率和線性函數.

* odds : $\frac{P_x}{1-P_x} \in (0, \infty)$
* log-odds : $ln(\frac{P_x}{1-P_x}) \in (-\infty, \infty)$

因為 log_odds 可以把 $P_x$ 轉換成在實數範圍內的結果, 所以模型使用 log-odds 來當連結函數.所以 

$g(P_x) = ln(\frac{P_x}{1-P_x}) = \beta_0 + \beta^TX$

可以得到,

$P(Y=1|X) = \frac{exp(\beta_0 + \beta^TX)}{1+exp(\beta_0 + \beta^TX)} \in [0,1]$

### Meaning of $\beta_1$

解釋 $\beta$ 的意義, 以 $\beta_1$ 為例.

從機率上來看, 若 $X_1$ 改變一單位, 用以下式子來看改變

$\frac{P(Y=1|X_1=X_1+1,...)}{1-P(Y=1|X_1=X_1+1,...)} / \frac{P(Y=1|X_1=X_1,...)}{1-P(Y=1|X_1=X_1,...)}$

已知 $\frac{P_x}{1-P_x} = exp(\beta_0 + \beta^TX)$

所以上面式子可以變成:

$exp(\beta_0 + \beta_1(X_1+1)+...)$ 和 $exp(\beta_0 + \beta_1(X_1)+...)$

兩個相除 $= e^{\beta_1}$

換句話說, $\beta_1$ 代表的意義為, 當 X_1 增加一單位時, odds 翻了 $exp(\beta_1)$ 倍.

從此結論可知, 假設 $\beta_1>0, \to \exp{\beta_1} > 1$. 也就是說 $odds(x_1 = X+1) > odds(x_1 = x)$.

又因odd的值和機率是一對一的, 所以:
$P(Y=1|X_1=x+1, ....) > P(Y=1|X_1=x, ....)$

所以從 $\beta$ 可以看出該變數是'危險因子'還是'保護因子'.

### 圖形參考(假設解釋變數只有1個)
![L12-1](figure\L13-1.PNG)


模型可以寫開成 : $ln(\frac{p_x}{1-p_x}) = \beta_0 + \beta^TX$, 這邊後面 $\beta$ 部分, <font color = red>和前面的線性回歸一樣, 可以放入虛擬變數或是交互作用項.</font>

另外, 單個參數和多個, 其得到的 $\beta$ 也不同(係數會不同). 並且在<font color = red>多個參數下, 如果係數為0不代表沒有解釋力, 是因為在其他變數存在的情況下沒有貢獻. </font> 這部分結論都和前面一樣.

### 參數相關

在 logis. reg., 如果有 p 個特徵則要估計 p+1 個參數(在一般線性回歸有 P+2個, 多一個 $\sigma^2$).

p+1個分別為 : $\beta_i,  i \in \{0, 1, ..., p\}$

資料 : $\{Y_i, X_i\}^n_{i=1}$

在給定X的情況下, 每個觀察值的機率為 $P_{X_i}^{Yi}(1-P_{X_i})^{Y_i}$, 這裡 $P_{X_i}= \frac{exp(\beta_0 + \beta^TX}{1+exp(\beta_0 + \beta^TX)}$.

從這可以得到, Likelihood func. : $L(\theta) = \prod{P_{X_i}^{Yi}(1-P_{X_i})^{Y_i}}$. 所以 MLE :$\theta=argmax_\theta L(\theta)$

# L14 Generalized Linear Model (3)

### Confidence Interval of $B_j$

$\hat{\beta}_j \pm \sqrt{Var(\hat{\beta}_j)}Z_{\frac{\alpha}{2}}$

### Testing

* $H_0 : \beta_j = \beta_j^*$

$Z = \frac{\hat{\beta}_j - \beta_j^*}{\sqrt{\hat{\beta}_j}} \sim N(0,1)$

## Likelihood Ratio Test (LRT)

類似 F test 的延伸, 用於檢定多個特徵是否為0.

$H_0 : \beta_{k+1} = ... = \beta_p = 0$

* Full model : 全部的特徵做的模型, $g(P_x) = \sum^p\beta_iX_i$
* Reduced model : 移除懷疑為0的特徵後的模型, $g(P_x) = \sum^k\beta_iX_i$

簡單來說, 兩個 Likelihood 得到的值, 若越接近則越不容易拒絕 $H_0$.
也就是 $T = \frac{L_f(\hat{\theta}_f)}{L_r(\hat{\theta}_r)}$ 越大, 越容易拒絕. 其中 $2lnT \sim X^2_{p-k}$.

這之中, 若 k = 1 代表檢定所有的特徵是否都無意義.

[詳細說明點這裡](https://youtu.be/8Qzqf51O6ZE?si=JfDDsnnhMtXkRnEr&t=635)

## Estimation of mean response

$\hat{P}_x = \frac{exp(\hat{\beta_0} + \hat{\beta}^T X)}{1 + exp(\hat{\beta_0} + \hat{\beta}^T X)} \in [0,1]$

因為 Y 為 0 or 1, 所以 Y 不能直接用 mean response 去當. 所以在 log. reg. 預測跟估計是不同的. 這實是去針對預測值去做二分類, 也就是

* $\hat{Y}_0 = 0 ~~ if~ \hat{P}_{X_0} \leq C ~else~ \hat{Y}_0 = 1$

其中, $\hat{P}_{X} > C \Longleftrightarrow \hat{\beta}_0 + \hat{\beta}^TX > ln\frac{c}{1-c}$

由此可畫出圖形類似如下:

![L14-1](figure\L14-1.PNG)

由此可知, 雖然預測時 mean response 是曲線的, 但在此做的分類是線性的, 也就是 Linear classifier.

# L15 Generalized Linear Model (4)

## 評估模型的好壞

可以去計算 maximum likelihood, 但因為變數越多, Likelihood 一定越大($L_f \geq L_r$), 所以不能直接去計算.

### 注意

<font size = 4 color = red>以下 AIC 和 BIC 似乎是錯的, 因為ln(L)前面應該是-的, 所以在課程中雖然說越大越好, 不過其實是越小越好.</font>

### AIC (Akaike Information Criterion)

在選擇模型時, 會考慮到模型解釋變數的數量, 類似 $adj\_R^2$.

$AIC \stackrel{\Delta}{=} lnL(\hat{\theta})-p$, 這邊的 p 是解釋變數的數量, 在公式中可以稱為懲罰項(penalty term)

### BIC (Bayesian information criterion)

和 AIC 類似, 但是這邊又考量到樣本數(n).

$BIC \stackrel{\Delta}{=} lnL(\hat{\theta}) - ln(n)*p$

### Misclassification rate

假設 cut-off = c, 若 $\hat{P}_x > c ~~ then ~~ y = 1$. 其中 $\hat{P}_x = \frac{exp(\beta^T X)}{1+exp(\beta^T X)}$

所以可以從 $X_i$ 推得 $\hat{P}_i$, 再推得 $\hat{Y}_i$, 之後利用其和 $Y_i$比較.

可以利用預測的Y和真實值比較, 得到錯誤分類率(Misclassification rate).

$MR(c) = \frac{no. \hat{Y}_i \neq Y_i}{n}$

不過這個分類率很容易 $P(Y=1)$ 影響, 也就是說, 若分類率會被真實的機率傾向影響. 若真實機率差異很大, 很容易會覺得爛的模型(全部猜1)很好.

其實不管怎樣的方法, 資料都是越 balanced 越好.

### ROC curve

sensitivity(敏感度, 真陽性率(TPR)) : $se(c) \stackrel{\Delta}{=} P(\hat{P}_x>c|Y=1) = \frac{\{no.~Y_i=1~and~\hat{P}_i>c\}}{\{no.~of~Y=1\}}$, 陽性分到陽性

specificity(特異度, 真陰性率 (TNR)) : $sp(c) \stackrel{\Delta}{=} P(\hat{P}_x\leq c|Y=0) = \frac{\{no.~Y_i=0~and~\hat{P}_i\leq c\}}{\{no.~of~Y=0\}}$, 陰性分到陰性

對於機率, $Y_i=0和1$ 可以繪製成圖(Y軸為估計機率)

![L15-1](figure\L15-1.PNG)

分類器越好期望來說 sp 和 se 越大越好. 因為 $\hat{p}$ 是可以計算的, 也就是說, 可以控制 c 至 0~1 找到最佳的 sp 和 se. 但由於控制 c 往左往右一定會使得 sp 或 se 變小, 所以必須取捨.

如果模型越好, 其實期望來說圖形的兩個波分得越開, 所以其實模型非常好的話有可能找到一個 c 使得 sp 和 se = 1. 最差是 sp + se = 1 for all c.

ROC curve : {( 1-sp(c), se(c) ) : c $\in$ (0,1)}
