<!-- markdownlint-disable MD033 -->

<!-- markdownlint-disable MD010 -->

<!-- markdownlint-disable MD037 -->

<!-- markdownlint-disable MD041 -->

<!-- markdownlint-disable MD024 -->

補 :

關於 mean response 和 預測 的差異可以去聽這段 : [L14](https://youtu.be/8Qzqf51O6ZE?si=2OPhPTORPz05FFLA&t=1308)

# L12 Generalized Linear Model

從此開始 Y 可能是離散型資料, 例如 Y = {0,1} 或 count data : {0, 1, 2, ...}

過去目標是得到 $Y = E[Y|X] + \epsilon$, 其中 $E[Y|X] = \beta_0 + \beta^TX$, $Y \sim N(E[Y|X], \sigma^2)$. 不過若 Y 為離散型, 則此結果會很奇怪.

當 Y 為 {0, 1} 時, $E[Y|X] = P(Y=1|X) \in [0, 1]$; 當 Y 為 {0, 1, ....}時, $E[Y|X]$ 也 $\in [0, 1]$

## 此時會用到的分佈

### Bernoulli

$Y~\sim Ber(p)$ with $p = P(Y=1)$.

* $f(y) = p^y(1-p)^{(1-y)},~ y = 0, 1$
* $E(Y) = p$
* $Var(Y) = p(1-p)$, 所以 p = 0.5 時變異最大.

### Poisson

$Y \sim Poi(\lambda)$

* $f(y) = \frac{e^{-\lambda}\lambda^y}{y!}$
* $E(Y) = \lambda$
* $Var(Y) = \lambda$

## Estimation of parameter

由 $Y_i \sim(iid) Ber(p)$ 來說

### likehood function

從假設給定 p, 求得 "看到目前資料的機率去推論" 最有可能的p.

看到目前資料的機率 $Y_i \to f_p(Y_i)$, 所以看到整組資料的機率為 $\prod f_p(Y_i) = L(p)$.

其值可畫出圖形類似如下:

![L12-1](figure\L12-1.PNG)

最高點代表是 該p的情況下 此資料最有可能出現, 找這點的估計方法稱為 MLE(最大概似估計, maximum likelihood estimation).

從式子可知道, $L(p) = \prod(p^{Y_i}(1-p)^{(1-Y_i)})$. 使用 log 和 微分最後推得出 $\hat{p} = \frac{1}{n}\sum Y_i$

## Inference rocedure

Model : $Y \sim f_\theta(y)$

Data : ${Y_i}$

Aim : estimate $\theta$ $\to$ 使用 MLE 估計.

# L13 Generalized Linear Model (2)

## Logistic Regression

* Binary response $Y \in \{0, 1\}$
* covariates : $X = (X_1, ..., X_p)$
* target : $E[Y|X] = P(Y=1|X) = P_x$

### Modeling

1. $Y|X \sim Bernoulli(P_x)$
2. $g(P_x) = \beta + \beta^TX$, g 稱為連結函數, 用來連結條件機率和線性函數.

* odds : $\frac{P_x}{1-P_x} \in (0, \infty)$
* log-odds : $ln(\frac{P_x}{1-P_x}) \in (-\infty, \infty)$

因為 log_odds 可以把 $P_x$ 轉換成在實數範圍內的結果, 所以模型使用 log-odds 來當連結函數.所以

$g(P_x) = ln(\frac{P_x}{1-P_x}) = \beta_0 + \beta^TX$

可以得到,

$P(Y=1|X) = \frac{exp(\beta_0 + \beta^TX)}{1+exp(\beta_0 + \beta^TX)} \in [0,1]$

### Meaning of $\beta_1$

解釋 $\beta$ 的意義, 以 $\beta_1$ 為例.

從機率上來看, 若 $X_1$ 改變一單位, 用以下式子來看改變

$\frac{P(Y=1|X_1=X_1+1,...)}{1-P(Y=1|X_1=X_1+1,...)} / \frac{P(Y=1|X_1=X_1,...)}{1-P(Y=1|X_1=X_1,...)}$

已知 $\frac{P_x}{1-P_x} = exp(\beta_0 + \beta^TX)$

所以上面式子可以變成:

$exp(\beta_0 + \beta_1(X_1+1)+...)$ 和 $exp(\beta_0 + \beta_1(X_1)+...)$

兩個相除 $= e^{\beta_1}$

換句話說, $\beta_1$ 代表的意義為, 當 X_1 增加一單位時, odds 翻了 $exp(\beta_1)$ 倍.

從此結論可知, 假設 $\beta_1>0, \to \exp{\beta_1} > 1$. 也就是說 $odds(x_1 = X+1) > odds(x_1 = x)$.

又因odd的值和機率是一對一的, 所以:
$P(Y=1|X_1=x+1, ....) > P(Y=1|X_1=x, ....)$

所以從 $\beta$ 可以看出該變數是'危險因子'還是'保護因子'.

### 圖形參考(假設解釋變數只有1個)

![L12-1](figure\L13-1.PNG)

模型可以寫開成 : $ln(\frac{p_x}{1-p_x}) = \beta_0 + \beta^TX$, 這邊後面 $\beta$ 部分, `<font color = red>`和前面的線性回歸一樣, 可以放入虛擬變數或是交互作用項.`</font>`

另外, 單個參數和多個, 其得到的 $\beta$ 也不同(係數會不同). 並且在`<font color = red>`多個參數下, 如果係數為0不代表沒有解釋力, 是因為在其他變數存在的情況下沒有貢獻. `</font>` 這部分結論都和前面一樣.

### 參數相關

在 logis. reg., 如果有 p 個特徵則要估計 p+1 個參數(在一般線性回歸有 P+2個, 多一個 $\sigma^2$).

p+1個分別為 : $\beta_i,  i \in \{0, 1, ..., p\}$

資料 : $\{Y_i, X_i\}^n_{i=1}$

在給定X的情況下, 每個觀察值的機率為 $P_{X_i}^{Yi}(1-P_{X_i})^{Y_i}$, 這裡 $P_{X_i}= \frac{exp(\beta_0 + \beta^TX}{1+exp(\beta_0 + \beta^TX)}$.

從這可以得到, Likelihood func. : $L(\theta) = \prod{P_{X_i}^{Yi}(1-P_{X_i})^{Y_i}}$. 所以 MLE :$\theta=argmax_\theta L(\theta)$

# L14 Generalized Linear Model (3)

### Confidence Interval of $B_j$

$\hat{\beta}_j \pm \sqrt{Var(\hat{\beta}_j)}Z_{\frac{\alpha}{2}}$

### Testing

* $H_0 : \beta_j = \beta_j^*$

$Z = \frac{\hat{\beta}_j - \beta_j^*}{\sqrt{\hat{\beta}_j}} \sim N(0,1)$

## Likelihood Ratio Test (LRT)

類似 F test 的延伸, 用於檢定多個特徵是否為0.

$H_0 : \beta_{k+1} = ... = \beta_p = 0$

* Full model : 全部的特徵做的模型, $g(P_x) = \sum^p\beta_iX_i$
* Reduced model : 移除懷疑為0的特徵後的模型, $g(P_x) = \sum^k\beta_iX_i$

簡單來說, 兩個 Likelihood 得到的值, 若越接近則越不容易拒絕 $H_0$.
也就是 $T = \frac{L_f(\hat{\theta}_f)}{L_r(\hat{\theta}_r)}$ 越大, 越容易拒絕. 其中 $2lnT \sim X^2_{p-k}$.

這之中, 若 k = 1 代表檢定所有的特徵是否都無意義.

[詳細說明點這裡](https://youtu.be/8Qzqf51O6ZE?si=JfDDsnnhMtXkRnEr&t=635)

## Estimation of mean response

$\hat{P}_x = \frac{exp(\hat{\beta_0} + \hat{\beta}^T X)}{1 + exp(\hat{\beta_0} + \hat{\beta}^T X)} \in [0,1]$

因為 Y 為 0 or 1, 所以 Y 不能直接用 mean response 去當. 所以在 log. reg. 預測跟估計是不同的. 這實是去針對預測值去做二分類, 也就是

* $\hat{Y}_0 = 0 ~~ if~ \hat{P}_{X_0} \leq C ~else~ \hat{Y}_0 = 1$

其中, $\hat{P}_{X} > C \Longleftrightarrow \hat{\beta}_0 + \hat{\beta}^TX > ln\frac{c}{1-c}$

由此可畫出圖形類似如下:

![L14-1](figure\L14-1.PNG)

由此可知, 雖然預測時 mean response 是曲線的, 但在此做的分類是線性的, 也就是 Linear classifier.

# L15 Generalized Linear Model (4)

## 評估模型的好壞

可以去計算 maximum likelihood, 但因為變數越多, Likelihood 一定越大($L_f \geq L_r$), 所以不能直接去計算.

### 注意

<font size = 4 color = red>以下 AIC 和 BIC 似乎是錯的, 因為ln(L)前面應該是-的, 所以在課程中雖然說越大越好, 不過其實是越小越好.`</font>`

### AIC (Akaike Information Criterion)

在選擇模型時, 會考慮到模型解釋變數的數量, 類似 $adj\_R^2$.

$AIC \stackrel{\Delta}{=} lnL(\hat{\theta})-p$, 這邊的 p 是解釋變數的數量, 在公式中可以稱為懲罰項(penalty term)

### BIC (Bayesian information criterion)

和 AIC 類似, 但是這邊又考量到樣本數(n).

$BIC \stackrel{\Delta}{=} lnL(\hat{\theta}) - ln(n)*p$

### Misclassification rate

假設 cut-off = c, 若 $\hat{P}_x > c ~~ then ~~ y = 1$. 其中 $\hat{P}_x = \frac{exp(\beta^T X)}{1+exp(\beta^T X)}$

所以可以從 $X_i$ 推得 $\hat{P}_i$, 再推得 $\hat{Y}_i$, 之後利用其和 $Y_i$比較.

可以利用預測的Y和真實值比較, 得到錯誤分類率(Misclassification rate).

$MR(c) = \frac{no. \hat{Y}_i \neq Y_i}{n}$

不過這個分類率很容易 $P(Y=1)$ 影響, 也就是說, 若分類率會被真實的機率傾向影響. 若真實機率差異很大, 很容易會覺得爛的模型(全部猜1)很好.

其實不管怎樣的方法, 資料都是越 balanced 越好.

### ROC curve

sensitivity(敏感度, 真陽性率(TPR)) : $se(c) \stackrel{\Delta}{=} P(\hat{P}_x>c|Y=1) = \frac{\{no.~Y_i=1~and~\hat{P}_i>c\}}{\{no.~of~Y=1\}}$, 陽性分到陽性

specificity(特異度, 真陰性率 (TNR)) : $sp(c) \stackrel{\Delta}{=} P(\hat{P}_x\leq c|Y=0) = \frac{\{no.~Y_i=0~and~\hat{P}_i\leq c\}}{\{no.~of~Y=0\}}$, 陰性分到陰性

對於機率, $Y_i=0和1$ 可以繪製成圖(Y軸為估計機率)

![L15-1](figure\L15-1.PNG)

分類器越好期望來說 sp 和 se 越大越好. 因為 $\hat{p}$ 是可以計算的, 也就是說, 可以控制 c 至 0~1 找到最佳的 sp 和 se. 但由於控制 c 往左往右一定會使得 sp 或 se 變小, 所以必須取捨.

如果模型越好, 其實期望來說圖形的兩個波分得越開, 所以其實模型非常好的話有可能找到一個 c 使得 sp 和 se = 1. 最差是 sp + se = 1 for all c.

ROC curve : {( 1-sp(c), se(c) ) : c $\in$ (0,1)}

備註 : sp -> specificity; se -> sensitivity

# L16 Generalized Linear Model (5)

## ROC

ROC curve : {( 1-sp(c), se(c) ) : c $\in$ (0,1)}

ROC : 可以較少被較高盛行率的對象所影響結果.

<font size = 4 color = red>ROC 曲線是用來反映 C 變動時 sp 和 se 的變化.`</font>` 另外因 sp 和 se 的變化是反向的, 所以 ROC 的 1-sp 和 se 就是同向的. 所以 <font size = 4 color =red>ROC 曲線一定是一個遞增函數.`</font>`

當 C = 1 時 sp = 1 且 se = 0, 所以位置為 (1-1,0)
當 C = 0 時 sp = 0 且 se = 1, 所以位置為 (1,0)

![L16-1](figure\L16-1.PNG)

理論上最好的 ROC 曲線一定經過 (0, 1), 也就是 sp = se = 1; 最差的為直接走 45度 線. 不是經過 (1, 0) 的原因在於, 經過 (1, 0) 就代表全部分類錯誤, 也就是 sp = se = 0. 換句話說把結果顛倒就會變成最好的了.

![L16-2](figure\L16-2.PNG)

### [補充](https://youtu.be/oTf3n-OD7EI?si=uZx7958yE6ets1yH&t=1437)

最差的 ROC 為斜線的原因在於, 該模型對於數據完全沒有預測力(模型計算的P和Y是獨立的)

## AUC

用來比較多個 ROC 曲線, 決定最佳的模型的方法, 可以使用 ROC 線下的面積. 因為 ROC 為遞增, 所以線下面積就是越靠近最佳 ROC 曲線的一條線.

ROC 的線下面積稱為 AUC.

### AUC 也有機率上的解釋

其代表意義為 : $AUC = P(P_X|Y=1 > P_X|Y=0)$. 也就是從 Y=1 和 Y=0 的結果中, 隨機抽出來的目標所計算的機率值, Y=1 所計算的結果 > Y=0 的結果 的機率為 AUC.

![L16-3](figure\L16-3.PNG)

# L17 Generalized Linear Model (6)

## Determination of C

希望決定一個C, 可以用 se(C) + sp(C) 求最大. 此 $C^*$ 又稱為 youden's index.

不過直接使用 se(C) + sp(C) 找最大不一定是最好, 因為<font size = 4 color = red>此情況是假設偽陽性跟偽陰性同樣嚴重`</font>`. 但實際情況可能不一定是這樣, 所以可以改成 a*sp(C) + se(C), a in (0,inf).

## [L17 model selection](https://youtu.be/Igo2EJPz3sU?si=lIngKW_FLhM_Bo37&t=729)

1. Dominated case : 若 model1 的 ROC 一定在 model2 的 ROC 上
   * 一定選擇 model1
2. Crossed case : model1 和 model2 的 ROC 曲線有交叉點(每有哪個model一定最大)
   * 這情況也有可能面積相等, 所以不一定能用面積去選擇(當然實際情況基本上不可能發生面積一樣).
   * 此情況則必須使用實際情況去選擇, 例如不希望 sp < 0.8, 則必須選擇 X 軸為 0~0.2 之間最大的 model(如圖).

![L17-1](figure\L17-1.PNG)

## Poisson Regression

當 Y 為 count data (Y=0,1,2,...)時, 建立模型(target E[Y|X]).

$Y|X \sim Poisson(\lambda x)$, 其中 $\lambda x = E[Y|X]$.

所以 model 目標是 $g(\lambda x) = \beta^T X$, with $g(u)=ln(u)$. 要取log的原因在於 poi 必須衡正, 所以不能直接對 $\lambda x$ 作模型.

其中, 如果要計算 $\lambda x$ 則直接取指數即可. 也就是 $\lambda x = \exp(\beta^T X)$

### beta 的意義

假設指變動 $X_1$ 1單位, 則 $\frac{E[Y|X_1=x+1, ...]}{E[Y|X_1=x, ...]} = \exp(\beta_1)$. 得到 $\exp(\beta_1)$ 是 mean ratio. 所以, $\beta$ 是 log(mean ratio). 也就是說 $\beta$ 為 log平均值上升的倍率.

* Poi. Reg. 的 beta 代表 X 上升 1 單位, 平均值會上升 $\exp(\beta)$倍
* log. Reg. 的 beta 是 odd 在翻倍
* 簡單線性回歸 的 beta 是 期望值直接變動.

## poi. reg. 估計

Data : $\{Y_i, X_i\}$, 假設 $Y_i|X_i \sim Poi(\lambda x_i)$

可得 $L(\theta) = \prod \frac{e^{-\lambda x_i}(\lambda x_i)^{Y_i}}{Y_i!}$

### 檢定方法

* 單點 $H_0 : \beta_j=0$為

$T = \frac{\hat{\beta}-0}{\sqrt{Var(\hat{\beta_j})}} \sim N(0,1)$

* 多個點 LRT : $H_0 : \beta_{k+1}=...=\beta_p=0$

使用 full model 和 reduced model 求比率.

$T = \frac{full model}{reduced model}$ 可以算 $2ln(T) \sim X^2_{p-k}$

# [L18 Generalized Linear Model (7)](https://www.youtube.com/watch?v=NVemOifoMqw&list=PLTp0eSi9MdkNZB4kyLSzIXIUy9JQOJ5AM&index=18)

## 進階 Poi. reg.

Poisson reg. 對於 (Y, X) 的 Y, 收集資料時不一定會是以相同長度去收集的.
例如 40 歲和 80 歲的抽菸人和其事件, 我們觀察的時間就不一定會一樣長, 這時必須針對觀察時間進行校正.

更改 data 變為 $(Y_i,m_i,X_i)$, 其中 m 為該 i 當下觀察 Y 所看的單位.

其模型會變成 $Y|X \sim Poi(E[Y|X])$, 其中 $E[Y|X] = m \lambda_x$.

建模的方法和一般Poi相同, 都是使用 log_link : $ln(\lambda_X) = \beta^TX \iff \lambda_X = e^{\beta^TX}$.

m 又稱 offset term.

### Likelihood func.

$L(\theta) = \prod \frac{e^{-m_i\lambda x_i}(m_i\lambda x_i)^{Y_i}}{Y_i!}$

### 針對 data

對於不同的觀測時間, 可以將結果除以期觀察單位($\frac{Y_i}{m_i}$), 讓所也觀察點的觀察單位都為 1.

若繪製圖形出來的結果很奇怪, 在建立模型時也可以考慮交互作用項等因素.

# L12 ~ L18 summary.

目的 : (Y,X) 去尋找 E(Y|X)

Y 的型態

1. Conti. Y : Linear Reg.
   * $Y|X  \sim N(E[|X], \sigma^2)$
   * $g(E[Y|X]) = \beta^TX$, with $g(u)=u$
2. Binary Y : Logistic Reg.
   * $Y|X  \sim Bern(E[|X])$, $E[Y|X] = P_X$
   * $g(E[Y|X]) = \beta^TX$, with $g(u)=ln\frac{u}{1-u}$
3. Count Y : Poisson Reg.
   * $Y|X  \sim Poi(E[|X])$, $E[Y|X] = m\lambda_X$
   * $g(\lambda_X) = \beta^TX$, with $g(u)=lnu$
