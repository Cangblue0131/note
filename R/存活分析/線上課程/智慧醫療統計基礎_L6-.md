<!-- markdownlint-disable MD033 -->
<!-- markdownlint-disable MD010 -->
<!-- markdownlint-disable MD037 -->
<!-- markdownlint-disable MD041 -->

# [L6 : Mean Response, Prediction, and Residual](https://www.youtube.com/watch?v=Ue1mgEVDwq0&list=PLTp0eSi9MdkNZB4kyLSzIXIUy9JQOJ5AM&index=6)

Estimation of Mean ResonseE, 以簡單線性回歸為例.

* $E[Y|X] = \beta_0 + \beta_1X => \widehat{E[Y|X]} = \hat{\beta}_0 + \hat{\beta}_1X$
* $Var(\widehat{E[Y|X]}) = \sigma^2[\frac{1}{n} + \frac{(X-\bar{X})^2}{Sxx}]$

## Hypothesis

$H_0 : E[Y|X] = \mu_0$

$T = \frac{(\hat{\beta}_0 + \hat{\beta}_1X) - \mu_0}{\hat{\sigma}^2[\frac{1}{n} + \frac{(X-\bar{X})^2}{Sxx}]} \sim t_{n-(p+1)}$

系賴區間 : 略

## Prediction

對於估計在 $X_0$ 下的值, 使用

* $Y_0 = \beta_0 + \beta_1X_0 + \epsilon_0$

其中因 $\epsilon_0 \sim N(0, \sigma^2)$. 所以對於估計, $\epsilon_0$ 可以直接帶0. 其他的 $\beta$ 則直接帶估計值.

<font size = 3 color = red>但是對於此預測, $Y_0$ 的變異會相較於 $\hat{Y}$ 來得大.</font> 原因在於在做預測時, 必須預測兩件事情, 一是 Mean Response; 二是 . 已知 Mean Response 的 Var, 所以是加上 $\epsilon$ 的變異.

* $Var(\hat{Y}_0) = \sigma^2[1 + \frac{1}{n} + \frac{(X_0-\bar{X})^2}{Sxx}]$

也就是說, $Y_0$(估計值) 的信賴區間會比較寬.

### $Y_0$ Hypothesis

$H_0 : Y_0 = \mu_0$

$T = \frac{\hat{Y}_0 - \mu_0}{\hat{\sigma}^2[1+\frac{1}{n} + \frac{(X_0-\bar{X})^2}{Sxx}]} \sim t_{n-(p+1)}$

## Note

### Note 1

在繪製 $\hat{E}[Y|X=x]$ 的信賴區間, 在圖形上會是曲線的, 在 $X=\bar{X}$ 時區間最窄. 原因在於統計量的計算上, X越接近 $\bar{X}$ 則越窄.

預測的信賴區間就相對於 $\hat{E}[Y|X=x]$ 的信賴區間多一個 $\sigma^2$.

![L6-1](figure\L6-1.PNG)

### Note 2

資料的範圍對於模型解釋是很重要的, 建議不要對模型進行外推(推測不在範圍外的結果), 因為模型可能和真實資料差異很大.

![L6-2](figure\L6-2.PNG)

## diagnosis of regression model

目的是檢查假設是否正確, 已知現有的假設有

* $Y = E[Y|X] + \epsilon$ 中的 $\epsilon$ 和 X 獨立.
* $E[Y|X] = \beta_0 + \beta_1X$
* $\epsilon \sim N(0, \sigma^2)$

所以要做檢查的有

1. $X$ 和 $\epsilon$ 是否獨立
2. $E[Y|X]$ 和 $\epsilon$ 是否獨立
3. $i$ 和 $\epsilon$ 無關
4. $\epsilon \sim N(0, \sigma^2)$

檢查方法可以使用畫圖去推論, 以下為上面四個分別畫的圖(不要太誇張就好)

1. plot of ${(X_u, e_i)}$
2. plot of ${(\hat{\beta}_0 + \hat{\beta}_1X_i, e_i)}$
3. ${(i, e_i)}$
4. ${(e_i)}$ 繪製 QQ plot

期望上1~3的圖形如下, 必須是以0為中心上下同力度震盪, 而不是像紅色那樣有關係性(X越大震盪越大).

![L6-3](figure\L6-3.PNG)

QQ plot 類似 :

![L6-4](figure\L6-4.PNG)

## Outlier Detection : 離群值診斷

直接看數據值, 會說離平均值來得遠的值為 Outlier; 在回歸分析中, 則是以建立出來的模型具決定, 也就是該值和估計值的距離(殘差)決定.

![L6-5](figure\L6-5.PNG)

### Testing

$T_i = \frac{e_i - 0}{\sqrt{Var(e_i)}} \sim t_{(n-(p+1))}$ 當 $H_0$ 成立時.

其中, $\widehat{Var}(e_i) = \hat{e}^2[1-(\frac{1}{n} + \frac{(X_i - \bar{X})^2}{Sxx})]$

此統計量每個資料點都能夠算, 所以可以得到每個資料點的 P_value. 也就是可以檢定每個點.

# L7 : Multiple Linear Regression(複回歸分析)) (1): 5 models

Response of interest : Y

Covariates : $X = (X_1, ..., X_p)$

Target : $E[Y|X]$

Model : $Y = E[Y|X] + \epsilon$

在線性回歸中, 也是假設此為線性關係. : $E[Y|X] = \beta_0 + \beta^TX$, $\epsilon \sim N(0, \sigma^2)$

所以總共需要估計的參數有 : $\theta = (\beta_0, ..., \beta_p, \sigma^2)$. 其中資料為$\{(X_{ip})\}$

<font size = 4>補 : Confouding</font>

好奇的特徵和目標在建模後雖然有關係, 但也有可能是因為其他特徵所導致的. 因此在未考慮到其他真正會影響的特徵, 可能會導致預測出現錯誤的解讀.

例如 : 預測後結論為藥物有效, 但其實因為收集資料時幾乎都收集到男性的, 且又未把性別放入特徵中, 導致無法正推論出真正原因.

## M1 : $Y = \beta_iX_i + \epsilon, i = 1 \sim2$

假設 $\beta_2$ 為性別

* $\beta_0 : 截距, 或說X都帶入0時的值(起始值)$
* $\beta_i, i \neq 0 :$ 再其他i不動的情況下, $X_i$ 每增加一單位時 Y 上升的幅度.
* 假設 $X_2$ 為離散資料(0 or 1). 則圖形就是兩個平行線, 斜率為 $\beta_1$, 兩條線的差距為 $\beta_2$.
* 若要檢定資料和性別是否無關, 則 $H_0 : \beta_2 = 0$
* 若要讓兩條線並非平行(斜率不同), 則可以加上交互作用項(interaction).

## M2 : $Y = \beta_iX_i + \beta_3(X_1X_2) + \epsilon, i = 1 \sim2$

interaction(交互作用) : 變數之間有關係(不獨立), 導致不同類別變相帶入後, 模型間不平行.

* 若要檢定資料和性別是否無關, 則 $H_0 : \beta_2 = \beta_3 = 0$
* 假設不知道模型用哪個, 又要檢定性別是否有影響, 可以使用比較複雜的模型進行. 不過用比較複雜的模型, 會使得估計的效度較低. 因再相同的資料量下, 要估計的變數較多, 所以越複雜的模型, 估計的變異會越大.
* 若要檢定成長速率是否和性別有關, 則是檢定 $H_0 : \beta_3 = 0$

# L8 Multiple Linear Regression (2): 5 models

## M3 : Categorical covariates with multiple levels

一個變數是多個值得類別變項, 就算是數值也沒有大小和數值關係, 此時不能直接使用. 因為複回歸的係數是各個類別的差距.

此時可以把這個變數拆分成多個虛擬變數(dummy variable), 各個變數分別對應一個類別, 且值為0或1. 用以表示是否為該項類別.

例如, $X = \{1, 2, 3\}$ 分別表示北中南. 此時可以改變, 新增兩個變數 $(X_1, X_2)$, 讓北中南分別對應 $\{(X_1, X_2)\} = \{(1, 0), (0, 1), (0, 0)\}$. 其中 $(0, 0)$ 又稱 reference level.

![L8-1](figure\L8-1.PNG)

所以模型會變成 : $Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3(X_1X_2) + \beta_{4(1)}X_{4(1)} + \beta_{4(2)}X_{4(2)} + \epsilon$

其中, 當 $X_{4(1)}$ 和 $X_{4(1)}$ 為 0 時, 代表得到的結果是參照基準(這邊是以南部為基準). 並且 $\beta_{4(1)}$ 和 $\beta_{4(2)}$ 分別是另外兩個地區和南部的差距 (北-南 或 中 - 南).

![L8-1](figure\L8-2.PNG)

### 檢定問題

* 地區是否有差異? -> $H_0 : \beta_{4(1)} = \beta_{4(2)} = 0$
* 北跟南有無差異? -> $H_0 : \beta_{4(1)} = 0$
* 北跟中有無差異? -> $H_0 : \beta_{4(1)} = \beta_{4(2)}$

關於第三個問題, 若變更 reference level 為中, 就只要檢定 $H_0 : \beta_{4(1)} = 0$ 即可. <font size = 3 color = red>所以不同模型, 雖然結果一樣, 但是會影響到檢定方法.</font>

## M4

$Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_{4(1)}X_{4(1)} + \beta_{4(2)}X_{4(2)} + \epsilon$

此模型和 M3 差別在沒有交互作用項, 所以各個線之間都是平行的.

此時要決定該使用 M3 還 M4, <font size = 3 color = red>注意不能使用 R-square.</font> 因為模型越複雜, R-square 一定越高. 應該使用 adj_R square.

### <font size = 4 color = red> Model selection</font>

以 M3 和 M4 為例

1. $adj\_R^2$
2. fit M3 後, 檢定 $\beta_3$
3. ...

## M5

若懷疑性別和地區也會影響斜率, 則

model : $Y = M3 + \beta_{5(1)}(X_{4(1)}X_1) + \beta_{5(2)}(X_{4(2)}X_1)$

* 若要檢定地區是否有影響 : $H_0 : \beta_{4(1)} = \beta_{4(2)} = \beta_{5(1)} = \beta_{5(2)} = 0$
* 檢定不同地區的成長趨勢是否有差 : $H_0 : \beta_{5(1)} = \beta_{5(2)} = 0$

## Note8

### 模型關係式

M1 $\subset$ (M2, M4) $\subset$ M3 $\subset$ M5, (越右邊越複雜)

模型選擇方法, 可以使用 $adj\_R^2$ 或 針對 $\beta$ 進行檢定.

### 模型限制

對於 M1 來說, 針對 Age 寫成 $\beta_1X_1$. <font size = 3 color = orange> 在這邊其實有假設 "年紀越大, 值越大" 這件事情(單調假設). </font> 若是曲線關係, 可以使用 "平方項" 或 "[分段改成類別變項](https://youtu.be/UB0kwppDucI?si=qtdgUFrtgYXZCQh8&t=3495)" 之類的方法去改變變數.

# L9  Multiple Linear Regression (3, 複迴歸)

對於 複迴歸, 需要估計的參數有 p+2 個 ($\beta_0, \beta_i  \{i=1 \sim p\}, \sigma$).

其中, $\beta_0$ 和 $\beta_i$ 的估計方法也是用 LSM, 也就是 $\sum(Y_i - \hat{Y}_i)^2$.

$\sigma$(誤差的變異) 一樣使用殘差估計, $\hat{e}^2 = \frac{1}{n-(p+1)}\sum(e_i-0)^2$, 其中 $e_i = Y_i - \hat{Y}_i$.

## R square

* SST = SSE + SSR
* $SST = \sum(Y_i - \bar{Y})^2$
* $SSE = \sum(Y_i - \hat{Y})^2$
* $SSR = \sum(\hat{Y}_i - \bar{Y})^2$
* $R^2 = 1 - \frac{SSE}{SST}$
  * $R^2 \in [0, 1]$
  * the propovtion of varication exlained by the model
  * $R^2 = [\varphi(Y_i, \hat{Y}_i)]^2$, 是估計和真實的相關係數之平方.

|   | SST        | SSE  | R  |
|---| -------- |:------:| -----:|
|dof| n-1      | n-(p+1)| p |

* $MST = \frac{SST}{n-1}$ : 用來估計 $Var(Y)$
* $MSE = \frac{SSE}{n-(p+1)}$ : 用來估計 $\sigma^2$
* $MSR = \frac{SSR}{p}$
* $adj\_R^2 = 1 - \frac{MSE}{MST} \leq 1$

換句話說, 校正的 $R^2$, 可以說是用來比較兩種 $Var$(分子和分母放不同Var).

## 假設檢定

### $H_0 :$ 模型沒用

$H_0 : \beta_i = 0, \forall i \neq 0$

* F-test : $F = \frac{MSR}{MSE} \sim F_{p,n-(p+1)}$

### $H_0 : \beta_j = \beta_j^*$, 檢定單一係數

$H_0 : \beta_i = 0$

* T-test : $T = \frac{\hat{\beta}_j - 0}{\widehat{Var}(\hat{\beta}_j)} \sim t_{n-(p+1)}$

## partial F-test : 用於同時檢定多個係數

Full Model : $Y = \beta_0 + \beta_iX_i + \epsilon, i \in [1, p]$

$H_0 : \beta_{k+1} = ... = \beta_p = 0$

若假設成立, 則回歸應變成為 Reducel Model : $Y = \beta_0 + \beta_iX_i + \epsilon, i \in [1, k]$

在 Full model 中, $SST = SSR_f + SSE_f$.

在 Reducel Model 中, $SST = SSR_r + SSE_r$.

其中, 都是SST的原依在於, 總變異一定是一樣的(和模型無關, 都是 $\sum(Y_i-\bar{Y})^2$).

也就是說, 兩個 model 有無差異是使用 SSR 來比較.

$F^* = \frac{(SSR_f - SSR_r)/(p-k)}{SSE_f/(n-(p+1))} \sim F_{p-k, n-(p+1)}$

## 信賴區間

### $H_0 : \beta_j = \beta_j^*$

$\hat{\beta} \pm t_{n-(p+1), \frac{\alpha}{2}}\sqrt{\hat{SE}(\hat{\beta}_j)}$

其他和此類似, 可由統計量直接推

## Estimation of Mean Response

$\widehat{E[Y|X]} = \hat{\beta}_0 + \hat{\beta}_iX_i, i \in [1, p]$

## Prediction

$\hat{Y_0} = \hat{\beta}_0 + \hat{\beta}_iX_i, i \in [1, p]$

預測和估計相同, 差別在於系賴區間的建議. 預測(Prediction) 會比較大, 多一個 $\sigma^2$, 來至於誤差的估計. 會有誤差要估計的原因在於, 預測值假設誤差為0.

## Residual Analysis(殘差分析)

* $X_i \perp \epsilon$ : 證明畫圖(散佈圖)
* $E[Y|X] \perp \epsilon$ : 證明畫圖
* $(i, \epsilon_i)$ : 證明畫圖
* $\epsilon \sim N(0, \sigma^2)$ : 證明畫圖(Q-Q plot)

可使用檢定看是不是離群值 :

$T = \frac{e_i}{\sqrt{\widehat{Var}(e_i)}} \sim t_{n-(p+1)}$
