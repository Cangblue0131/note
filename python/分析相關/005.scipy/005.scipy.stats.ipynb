{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scipy.stats\n",
    "\n",
    "* <font size = 5>簡述 : </font>\n",
    "\n",
    "    scipy.stats 是 SciPy(Scientific Python) 庫中的一個子模塊, 有執行各種統計學相關的功能. 它提供許多統計學上的分佈、統計檢定、樣本生成和機率計算等功能.\n",
    "\n",
    "* <font size = 5>功能 : </font>\n",
    "\n",
    "    * 機率分佈 : scipy.stats 提供了許多常見的概率分佈的函數。可以使用這些函數來計算概率密度函數（PDF）、累積分佈函數（CDF）、百分位點（Percent Point Function，PPF）等。\n",
    "    * 統計檢定 : scipy.stats 提供了多種統計檢定的函數，如t檢定（單樣本t檢定、獨立樣本t檢定、配對樣本t檢定）、卡方檢定（卡方適合度檢定、卡方獨立性檢定）、ANOVA（單因素變異數分析）等。\n",
    "    * 樣本生成 : scipy.stats 提供了許多概率分佈的樣本生成函數，如 rvs 函數可以生成從指定分佈中抽取的隨機樣本，這對於模擬和數據生成很有用.\n",
    "    * 概率計算 : scipy.stats 提供了許多概率計算的函數，比如計算離散或連續分佈的期望值、變異數、偏度、峰度等。\n",
    "    * 擬合分佈 : scipy.stats 提供了一些擬合分佈的函數，可以通過最大似然估計（MLE）將觀測數據擬合到指定的分佈。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 機率分佈\n",
    "\n",
    "<font color = orange> 為了方便, 以下都已 ss 代表 scipy.stats (也就是說 import scipy.stats as ss)</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 常用的機率分佈有以下幾個\n",
    "\n",
    "1. 常態分佈（Normal Distribution）：在統計學和自然科學中最常見的分佈，也稱為高斯分佈。\n",
    "    \n",
    "    code 寫法 : norm_dist = ss.norm(loc=mean, scale=std) # std 是標準差\n",
    "---\n",
    "2. 二項分佈（Binomial Distribution）：描述在n次獨立試驗中成功的次數的分佈。\n",
    "\n",
    "    code 寫法 : binom_dist = ss.binom(n=n_trials, p=p_success) # n 是數量, p 是成功機率\n",
    "---\n",
    "3. 普瓦松分佈（Poisson Distribution）：用於描述在固定時間間隔內發生事件的次數。\n",
    "\n",
    "    code 寫法 : poisson_dist = ss.poisson(mu=lambda_poisson)\n",
    "--- \n",
    "4. gamme 分佈（Gamma Distribution）：描述連續事件的時間間隔，也用於描述連續分佈的和。\n",
    "\n",
    "    code 寫法 : gamma_dist = ss.gamma(a=alpha, scale=1/beta)\n",
    "---\n",
    "5. 指數分佈（Exponential Distribution）：描述連續事件之間的等待時間。\n",
    "\n",
    "    code 寫法 : exponential_dist = ss.expon(scale=1/lambda_exponential)\n",
    "---\n",
    "6. t分佈（t-distribution）：用於小樣本情況下，對母體均值進行推斷的統計分佈。\n",
    "\n",
    "    code 寫法 : t_dist = ss.t(df=df_t)\n",
    "---\n",
    "7. F分佈（F-distribution）：用於進行兩個或多個樣本的方差比較的統計分佈。\n",
    "\n",
    "    code 寫法 : f_dist = ss.f(dfn=df1_f, dfd=df2_f)\n",
    "---\n",
    "8. 卡方分佈（Chi-Square Distribution）：用於進行卡方檢定的統計分佈。\n",
    "\n",
    "    code 寫法 : chi2_dist = ss.chi2(df=df_chi2)\n",
    "---\n",
    "9. 負二項分佈（Negative Binomial Distribution）：描述在n次獨立試驗中成功的次數之前出現k次失敗的次數。\n",
    "\n",
    "    code 寫法 : neg_binom_dist = ss.nbinom(n=n_failures, p=p_failure)\n",
    "------\n",
    "10. Beta分佈（Beta Distribution）：用於描述介於0和1之間的隨機變數。\n",
    "\n",
    "    code 寫法 : beta_dist = ss.beta(a=alpha, b=beta)\n",
    "---\n",
    "11. 柏努利分佈（Bernoulli Distribution）：描述僅有兩個可能結果（成功或失敗）的試驗。\n",
    "\n",
    "    code 寫法 : bernoulli_dist = ss.bernoulli(p=p_bernoulli)\n",
    "---\n",
    "12. 離散均勻分佈（Discrete Uniform Distribution）：用於描述在有限範圍內等可能事件的分佈。\n",
    "\n",
    "    code 寫法 : discrete_uniform_dist = ss.randint(low, high+1)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分佈的使用方法\n",
    "\n",
    "以上 code 皆可以使用以下方式創建想創建的(這邊以normal為例 : norm_dist = ss.norm(loc = mean, scale = std))\n",
    "\n",
    "1. pdf : 機率值\n",
    "\n",
    "    norm_dist.pdf(x = x)\n",
    "\n",
    "2. cdf : 累積機率\n",
    "\n",
    "    norm_dist.cdf(x = x)\n",
    "\n",
    "3. ppf : 百分位點\n",
    "\n",
    "    norm_dist.ppf(q = q)\n",
    "\n",
    "4. 模擬資料\n",
    "\n",
    "    norm_dist.rvs(size = size)\n",
    "\n",
    "5. 計算期望值\n",
    "\n",
    "    norm_dist.mean()\n",
    "\n",
    "6. 計算變異數\n",
    "\n",
    "    norm_dist.var()\n",
    "\n",
    "7. 計算偏度\n",
    "\n",
    "    norm_dist.stats(moments = 's') # 描述分佈的對稱性, 0 為對稱, > 0 則為右偏\n",
    "\n",
    "8. 計算峰度\n",
    "\n",
    "    norm_dist.stats(moments = 'k') # 用於描述概率分佈尾部形狀的統計量, 以常態分佈來說，峰度的值為 3，這種峰度稱為「正常峰度」。如果峰度大於 3，則稱為「高峰度」（尖峭分佈）；如果峰度小於 3，則稱為「低峰度」（扁平分佈）。\n",
    "\n",
    "9. 計算矩(E[X^k])\n",
    "\n",
    "    norm_dist.stats(moments = 'm3') # 計算E[X^3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python\n",
    "以 normal 為例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_dist.pdf(0) = 0.3989422804014327\n",
      "norm_dist.cdf(0) = 0.5\n",
      "norm_dist.ppf(0) = 0.0\n",
      "simulation : \n",
      " [-1.66752065 -0.40014461 -1.26177926  1.5382646   1.43262603  1.0299588\n",
      " -0.01051209 -0.47103178  1.2640744   0.29089419  0.9572153  -0.37315234\n",
      " -2.64334059 -0.27583328 -0.90495662 -0.33055411 -0.10026091 -1.30813866\n",
      " -0.58028265 -1.67716757 -0.43983896 -0.58787222 -0.46565488 -0.61025017\n",
      "  1.25145935 -1.10355545 -0.1539752   0.82194488 -0.27752834  0.75965813]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as ss\n",
    "\n",
    "norm_dist = ss.norm(loc = 0, scale = 1)\n",
    "print('norm_dist.pdf(0) = {}'.format(norm_dist.pdf(x = 0)))\n",
    "print('norm_dist.cdf(0) = {}'.format(norm_dist.cdf(x = 0)))\n",
    "print('norm_dist.ppf(0) = {}'.format(norm_dist.ppf(q = 0.5)) )\n",
    "sample_normal = norm_dist.rvs(size = 30)\n",
    "print('simulation : \\n', sample_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_dist.mean() = 3.0\n",
      "norm_dist.var() = 4.0\n",
      "norm_dist.stats(moments = \"s\") = 0.0\n",
      "norm_dist.stats(moments = \"k\") = 0.0\n",
      "norm_dist.stats(moments = \"m4\") = 3.0\n"
     ]
    }
   ],
   "source": [
    "norm_dist = ss.norm(loc = 3, scale = 2)\n",
    "print('norm_dist.mean() = {}'.format(norm_dist.mean()))\n",
    "print('norm_dist.var() = {}'.format(norm_dist.var()))\n",
    "print('norm_dist.stats(moments = \"s\") = {}'.format(norm_dist.stats(moments = \"s\")))\n",
    "print('norm_dist.stats(moments = \"k\") = {}'.format(norm_dist.stats(moments = \"k\")))\n",
    "print('norm_dist.stats(moments = \"m4\") = {}'.format(norm_dist.stats(moments = \"m3\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 統計檢定\n",
    "\n",
    "1. 單樣本 T 檢定 (one-sample t test) : 用於比較 sample的平均數 和 虛無假設(H0) 是否具有統計上的差異\n",
    "\n",
    "    t_statistic, p_value = ss.ttest_1samp(sample, null_mean) # null_mean : H0\n",
    "2. 獨立樣本 T 檢定 (Independent t test) : 用於比較 sample_A 和 sample_B 的樣本平均數是否具有統計上的差異\n",
    "\n",
    "    t_statistic, p_value = ss.ttest_ind(sample_A, sample_B)\n",
    "3. 成對樣本 T 檢定 (Paired t-test) : 用於比較 事前資料(before_exam) 和 事後資料(after_exam) 的樣本平均數是否具有統計上的差異\n",
    "\n",
    "    t_statistic, p_value = ss.ttest_rel(before_exam, after_exam) \n",
    "---\n",
    "4. 單因子 ANOVA (one_way ANOVA) : 用於比較三個或三個以上樣本平均數是否具有統計上的差異 (比較兩個和 t-test 一樣意思)\n",
    "\n",
    "    f_statistic, p_value = ss.f_oneway(sample_A, sample_B, sample_C, ...)\n",
    "---\n",
    "5. 雙因子 ANOVA 非重複試驗\n",
    "\n",
    "    需使用到 \"statsmodels.formula.api import ols\" 和 \"from statsmodels.stats.anova import anova_lm\",\n",
    "    或是使用 \"statsmodels.formula.api import ols\" 和 \"import statsmodels.api as sm\", sm.stats.anova_lm(model, typ = type), # type = 1, 2, 3\n",
    "    ```python\n",
    "    formula = 'measurements ~ C(factor_A) + C(factor_B) + C(factor_A):C(factor_B)'  # 通常非重複試驗不需要加入交互作用項, 不過其實加了也沒關係\n",
    "    model = ols(formula, data=data).fit()\n",
    "    anova_table = anova_lm(model)\n",
    "    ```\n",
    "    \n",
    "6. 雙因子 ANOVA 重複試驗\n",
    "\n",
    "    和上面相同, 但是一定要有交互作用項\n",
    "\n",
    "    補充 type :\n",
    "\n",
    "    1：計算基於 Type-I 方法的 ANOVA 表格。這種方法將因子逐一加入模型，計算每個因子的主要效應和交互作用效應，然後進行比較。這種方法通常用於處理平衡設計的數據，即每個細胞（cell）中的觀測值數量相等。\n",
    "\n",
    "    2：計算基於 Type-II 方法的 ANOVA 表格。這種方法通常用於處理非平衡設計的數據，即每個細胞中的觀測值數量不等。Type-II 方法會考慮每個因子的主要效應和交互作用效應，但在計算主要效應時，會將其他因子納入模型進行調整。\n",
    "    \n",
    "    3：計算基於 Type-III 方法的 ANOVA 表格。這種方法也用於處理非平衡設計的數據。Type-III 方法會考慮每個因子的主要效應和交互作用效應，並且在計算主要效應時，會同時考慮其他因子的交互作用效應。\n",
    "\n",
    "    選擇適合的 typ 參數取決於您的數據的設計和研究問題。如果您的數據是平衡設計（每個細胞中的觀測值數量相等），則通常可以使用 typ=1 或 typ=2。如果您的數據是非平衡設計，則建議使用 typ=3，因為這樣可以更全面地考慮所有主要效應和交互作用效應。\n",
    "---\n",
    "7. 卡方Goodness of Fit Test (適合度檢定) : 樣本與母體分布是否相似。(不同咖啡喜好度是否一樣)\n",
    "\n",
    "    ```python\n",
    "    from scipy.stats import chisquare\n",
    "    chi2, p_value = chisquare(observed_counts, expected_counts) # 實驗結果, 期望結果\n",
    "    ```\n",
    "8. 卡方Tests of Independence (獨立性檢定) : 各類別是否獨立。(男女和科系是否相關)\n",
    "\n",
    "    ```python\n",
    "    from scipy.stats import chi2_contingency\n",
    "    chi2, p_value, dof, expected = chi2_contingency(cross_tab) # 交叉表\n",
    "    ```\n",
    "9.  卡方Tests of Homogeneity(齊一性檢定) : 檢定兩個或兩個以上不同的母體是否具有相同的分配或相同的比例。(不同店家的滿意度比例是否相同)\n",
    "\n",
    "    ```python\n",
    "    from scipy.stats import chi2_contingency\n",
    "    chi2_statistic, p_value, dof, expected = chi2_contingency([sample_A, sample_B])\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python 1\n",
    "\n",
    "兩個樣本, 使用 t-test 和 ANOVA 結果相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t_statistic = -4.146139914483855\n",
      "p_value = 0.003226037919118031\n",
      "f_statistic = 17.19047619047619\n",
      "p_value = 0.0032260379191180327\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "sample_A = np.array([5, 7, 6, 8, 5])\n",
    "sample_B = np.array([9, 10, 11, 12, 8])\n",
    "\n",
    "t_statistic, p_value = ss.ttest_ind(sample_A, sample_B)\n",
    "print(\"t_statistic = {}\".format(t_statistic))\n",
    "print(\"p_value = {}\".format(p_value))\n",
    "\n",
    "f_statistic, p_value = ss.f_oneway(sample_A, sample_B)\n",
    "print(\"f_statistic = {}\".format(f_statistic))\n",
    "print(\"p_value = {}\".format(p_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python 2\n",
    "\n",
    "重複試驗的 two-way anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      sum_sq    df             F        PR(>F)\n",
      "Intercept       2.420000e+03   1.0  4.360360e+02  4.916069e-13\n",
      "Treatment       2.560000e+01   1.0  4.612613e+00  4.740159e-02\n",
      "Time            4.900000e+00   1.0  8.828829e-01  3.613831e-01\n",
      "Treatment:Time  3.466674e-28   1.0  6.246259e-29  1.000000e+00\n",
      "Residual        8.880000e+01  16.0           NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "#import numpy as np\n",
    "import pandas as pd\n",
    "#import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "# 假設有一組受試者在前測和後測下接受了兩種不同處理條件\n",
    "data = pd.DataFrame({\n",
    "    'Subject': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'Treatment': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'],\n",
    "    'Pretest': [20, 18, 25, 23, 22, 19, 24, 21, 26, 20],\n",
    "    'Posttest': [18, 16, 23, 22, 21, 17, 23, 20, 25, 19]\n",
    "})\n",
    "\n",
    "# 將數據轉換為長格式（Long format），便於進行重複試驗的 two-way ANOVA\n",
    "data_long = pd.melt(data, id_vars=['Subject', 'Treatment'], var_name='Time', value_name='Measurement')\n",
    "\n",
    "# 建立重複試驗的 two-way ANOVA 模型\n",
    "formula = 'Measurement ~ Treatment + Time + Treatment:Time'\n",
    "model = ols(formula, data=data_long).fit()\n",
    "\n",
    "# 計算重複試驗的 two-way ANOVA 表格\n",
    "anova_table = anova_lm(model, typ=3)\n",
    "\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python 3\n",
    "\n",
    "卡方-適合度檢定（Goodness-of-Fit Test）: 樣本與母體分布是否相似, H0 : 相似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Statistic: 3.08\n",
      "P-value: 0.687653573163054\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# 假設投擲結果\n",
    "observed_counts = np.array([20, 15, 18, 20, 12, 15])\n",
    "\n",
    "# 期望的均勻分佈，假設每個面出現的概率應該是 1/6\n",
    "expected_counts = np.array([100/6, 100/6, 100/6, 100/6, 100/6, 100/6])\n",
    "\n",
    "# 進行適合度檢定\n",
    "chi2, p_value = chisquare(observed_counts, expected_counts)\n",
    "\n",
    "print(\"Chi-Square Statistic:\", chi2)\n",
    "print(\"P-value:\", p_value) # H0 : 相似"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python 4\n",
    "\n",
    "卡方獨立性檢定（Tests of Independence）：各類別是否獨立, H0 : 獨立(以此例子來說, 性別不會影響結果)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Square Statistic: 0.6666666666666666\n",
      "P-value: 0.7165313105737892\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# 假設問卷調查數據\n",
    "data = pd.DataFrame({\n",
    "    'Gender': ['Male', 'Male', 'Female', 'Male', 'Female', 'Female', 'Male', 'Female'],\n",
    "    'Preference': ['A', 'B', 'B', 'A', 'A', 'C', 'C', 'C']\n",
    "})\n",
    "\n",
    "# 建立交叉表\n",
    "cross_tab = pd.crosstab(data['Gender'], data['Preference'])\n",
    "\n",
    "# 進行獨立性檢定（卡方檢定）\n",
    "chi2, p_value, dof, expected = chi2_contingency(cross_tab)\n",
    "\n",
    "print(\"Chi-Square Statistic:\", chi2)\n",
    "print(\"P-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python 5\n",
    "Tests of Homogeneity(齊一性檢定) : 檢定兩個或兩個以上不同的母體是否具有相同的分配或相同的比例。 H0 : 有相同分配(兩者相似)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "卡方統計量: 1.399957478538031\n",
      "p-value: 0.8442024068483136\n",
      "自由度: 4\n",
      "期望值:\n",
      " [[82.97359357 89.510907   89.00803674 89.00803674 87.49942595]\n",
      " [82.02640643 88.489093   87.99196326 87.99196326 86.50057405]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# 假設抽樣結果\n",
    "factory1 = np.array([80, 90, 95, 85, 88])\n",
    "factory2 = np.array([85, 88, 82, 92, 86])\n",
    "\n",
    "# 進行齊一性檢定（卡方檢定）\n",
    "chi2_statistic, p_value, dof, expected = chi2_contingency([factory1, factory2])\n",
    "\n",
    "print(\"卡方統計量:\", chi2_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "print(\"自由度:\", dof)\n",
    "print(\"期望值:\\n\", expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算樣本相關\n",
    "\n",
    "1. 計算期望值\n",
    "\n",
    "    np.mean(sample)\n",
    "---\n",
    "2. 計算變異數\n",
    "\n",
    "    np.var(sample, ddof = 1) # ddof = 1 即為計算樣本變異數\n",
    "---\n",
    "3. 計算標準差\n",
    "\n",
    "    np.std(sample, ddof = 1)\n",
    "---\n",
    "4. 計算偏度\n",
    "\n",
    "    ss.skew(sample)\n",
    "---\n",
    "5. 計算峰度\n",
    "\n",
    "    ss.kurtosis(sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample mean = 5.042345100398683\n",
      "sample var = 2.076230693658583\n",
      "sample std = 1.4409131457720077\n",
      "sample std(使用var^(1/2)) = 1.4409131457720077\n",
      "sample 偏度 = 1.4333297667074685\n",
      "sample 峰度 = 3.1038736334470247\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "# simulation\n",
    "np.random.seed(13)\n",
    "gamma_dis = ss.gamma(2,3)\n",
    "sample = gamma_dis.rvs(size = 5000)\n",
    "\n",
    "# mean\n",
    "sample_mean = np.mean(sample)\n",
    "\n",
    "# var\n",
    "sample_var = np.var(sample, ddof = 1)\n",
    "\n",
    "# std\n",
    "sample_std = np.std(sample, ddof = 1)\n",
    "\n",
    "# 偏度\n",
    "sample_skew = ss.skew(sample)\n",
    "\n",
    "# 峰度\n",
    "sample_kurtosis = ss.kurtosis(sample)\n",
    "\n",
    "print(\"sample mean = {}\".format(sample_mean))\n",
    "print(\"sample var = {}\".format(sample_var))\n",
    "print(\"sample std = {}\".format(sample_std))\n",
    "print(\"sample std(使用var^(1/2)) = {}\".format(np.sqrt(sample_var)))\n",
    "print(\"sample 偏度 = {}\".format(sample_skew))\n",
    "print(\"sample 峰度 = {}\".format(sample_kurtosis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 擬合分佈\n",
    "\n",
    "樣本可以使用 fit 去估計所決定之分佈的參數值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 12.034144206871968\n",
      "Standard Deviation: 3.982816782204311\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "np.random.seed(13)\n",
    "norm_dis = ss.norm(loc = 3, scale = 2)\n",
    "sample = (norm_dis.rvs(size = 5000) + 3)*2 # mean 變為12, std 變為 4\n",
    "\n",
    "# 假設擬合的概率分佈是常態分佈，則進行擬合\n",
    "# fit() 函數將返回一個包含估計的分佈參數的元組 (loc, scale)\n",
    "params = ss.norm.fit(sample)\n",
    "\n",
    "# 分別提取均值和標準差\n",
    "mean, std = params\n",
    "\n",
    "print(\"Mean:\", mean)\n",
    "print(\"Standard Deviation:\", std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
