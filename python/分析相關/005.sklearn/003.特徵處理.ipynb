{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 特徵處理\n",
    "\n",
    "當然除了這些還有其他方法, 參考 012.特徵相關.\n",
    "\n",
    "1. PCA : 降維\n",
    "2. AutoFeat : 升維\n",
    "3. 相關性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA(主成分分析) : 降維\n",
    "\n",
    "用來降低維度, 且保留數據的主要訊息."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个维度的主成分(PC)值 : \n",
      "维度 1: [-0.31644095  0.38832581  0.37263919 -0.08200572 -0.3611503   0.14104365\n",
      " -0.24575502  0.08832903  0.48643738  0.38515135]\n",
      "维度 2: [-0.04233586  0.2798924   0.31062378 -0.14507819 -0.15805849 -0.49418697\n",
      " -0.18461535  0.45284893 -0.50331272 -0.20162139]\n",
      "维度 3: [-0.02214896  0.37802299  0.11591659  0.36181336  0.59020145  0.2330573\n",
      " -0.49203875 -0.16012417 -0.20412184  0.014192  ]\n",
      "\n",
      "每個维度的解釋度 : \n",
      "维度 1: 0.1611\n",
      "维度 2: 0.1390\n",
      "维度 3: 0.1180\n",
      "维度 4: 0.1063\n",
      "维度 5: 0.0968\n",
      "维度 6: 0.0883\n",
      "维度 7: 0.0859\n",
      "维度 8: 0.0775\n",
      "维度 9: 0.0679\n",
      "维度 10: 0.0593\n",
      "\n",
      "累積方差解釋率 : \n",
      "前 1 個维度累積方差解釋率：0.1611\n",
      "前 2 個维度累積方差解釋率：0.3001\n",
      "前 3 個维度累積方差解釋率：0.4181\n",
      "前 4 個维度累積方差解釋率：0.5244\n",
      "前 5 個维度累積方差解釋率：0.6212\n",
      "前 6 個维度累積方差解釋率：0.7095\n",
      "前 7 個维度累積方差解釋率：0.7953\n",
      "前 8 個维度累積方差解釋率：0.8728\n",
      "前 9 個维度累積方差解釋率：0.9407\n",
      "前 10 個维度累積方差解釋率：1.0000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# 生成示例数据\n",
    "np.random.seed(42)\n",
    "data = np.random.rand(100, 10)\n",
    "\n",
    "# 创建PCA对象，并拟合数据\n",
    "pca = PCA()\n",
    "pca.fit(data)\n",
    "\n",
    "# 获取每个维度的解释度和累计方差解释率\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance)\n",
    "\n",
    "print(\"每个维度的主成分(PC)值 : \")\n",
    "for i in range(min(3,np.shape(data)[1])):\n",
    "    print(f\"维度 {i+1}: {pca.components_[i]}\")\n",
    "\n",
    "# 输出每个维度的解释度和累计方差解释率\n",
    "print(\"\\n每個维度的解釋度 : \")\n",
    "for i, ev in enumerate(explained_variance):\n",
    "    print(f\"维度 {i+1}: {ev:.4f}\")\n",
    "\n",
    "print(\"\\n累積方差解釋率 : \")\n",
    "for i, cev in enumerate(cumulative_explained_variance):\n",
    "    print(f\"前 {i+1} 個维度累積方差解釋率：{cev:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "回歸模型系数： [-80.06685648  84.98259857  45.76534356 -32.28268893  66.9524704\n",
      "  68.45640835 -55.75366454]\n",
      "回歸模型截距： 11.013216414049733\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 生成模拟数据\n",
    "X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=42)\n",
    "\n",
    "# 使用PCA进行降维\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# 計算主成分的解釋度\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# 計算累積解釋度\n",
    "cumulative_explained_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# 找到累积解释方差大于等于0.8的主成分的数量\n",
    "n_components = np.argmax(cumulative_explained_variance_ratio >= 0.8) + 1 #求累積解釋率 >= 0.8 的位置\n",
    "\n",
    "# 取出累积解释方差大于等于0.8的主成分\n",
    "X_pca_selected = X_pca[:, :n_components]\n",
    "\n",
    "# 使用回归模型进行分析\n",
    "regression_model = LinearRegression()\n",
    "regression_model.fit(X_pca_selected, y)\n",
    "\n",
    "# 输出模型的系数和截距\n",
    "print(\"回歸模型系数：\", regression_model.coef_)\n",
    "print(\"回歸模型截距：\", regression_model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoFeat : 升維\n",
    "\n",
    "有些資料必須使用高維度去分析, 例如 y = X1^2 + X2^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始資料形狀： (5, 2)\n",
      "特徵提升後資料形狀： (5, 3)\n",
      "原始特徵名稱： Index(['X1', 'X2'], dtype='object')\n",
      "新特徵名稱： Index(['X1', 'X2', 'exp(X2)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from autofeat import AutoFeatRegressor\n",
    "\n",
    "# 假設這是我們的資料\n",
    "data = pd.DataFrame({\n",
    "    'X1': [1, 2, 3, 4, 5],\n",
    "    'X2': [2, 3, 4, 5, 6],\n",
    "    'y': [5, 13, 25, 41, 61]\n",
    "})\n",
    "\n",
    "# 分割特徵和目標變數\n",
    "X = data[['X1', 'X2']]\n",
    "y = data['y']\n",
    "\n",
    "# 建立 AutoFeatRegressor 物件\n",
    "reg = AutoFeatRegressor()\n",
    "\n",
    "# 使用 fit 函數進行特徵提升\n",
    "X_transformed = reg.fit_transform(X, y)\n",
    "\n",
    "# 取得新特徵名稱\n",
    "new_feat_names = X_transformed.columns\n",
    "\n",
    "print(\"原始資料形狀：\", X.shape)\n",
    "print(\"特徵提升後資料形狀：\", X_transformed.shape)\n",
    "print(\"原始特徵名稱：\", X.columns)\n",
    "print(\"新特徵名稱：\", new_feat_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recursive Feature Elimination (RFE)：RFE是一种递归特征消除方法，它通过反复训练模型并剔除最不重要的特征来选择特征。可以使用sklearn的RFE类来实现。\n",
    "\n",
    "SelectKBest和SelectPercentile：这是一种基于统计检验的特征选择方法，它根据指定的统计指标（例如卡方检验、F检验、互信息等）选择排名前k个特征或排名前k%的特征。可以使用sklearn的SelectKBest和SelectPercentile类来实现。\n",
    "\n",
    "SelectFromModel：这是一种基于模型的特征选择方法，它通过训练一个模型，并选择重要性高于指定阈值的特征。可以使用sklearn的SelectFromModel类来实现。\n",
    "\n",
    "VarianceThreshold：这是一种简单的特征选择方法，它根据特征的方差来进行选择，只保留方差大于指定阈值的特征。可以使用sklearn的VarianceThreshold类来实现。\n",
    "\n",
    "Boruta：Boruta是一种基于随机森林的特征选择方法，它通过比较原始特征和随机重排特征的重要性来选择特征。可以使用第三方库boruta来实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
