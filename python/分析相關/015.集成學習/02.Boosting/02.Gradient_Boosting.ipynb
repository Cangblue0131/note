{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting\n",
    "\n",
    "Gradient Boosting 的主要思想是，每個新的弱學習器都嘗試修正之前模型的預測結果中的錯誤部分。這是通過擬合一個弱學習器來逼近之前模型的預測誤差的負梯度（Gradient）來實現的。這樣，每個新的模型都會試圖將整體模型的預測結果向正確的方向調整。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟簡述\n",
    "\n",
    "1. 初始化模型：起初，使用一個基本的弱學習器，如淺層決策樹，作為起點。\n",
    "\n",
    "2. 計算殘差：計算目前模型的預測值和實際目標之間的差距，稱為殘差。\n",
    "\n",
    "3. 訓練新模型：建立一個新的弱學習器，該模型嘗試預測之前模型的殘差。這麼做的目的是糾正模型的預測誤差。\n",
    "\n",
    "4. 整合新模型：將新的弱學習器與之前的模型結合，透過一定的權重將它們的預測結果結合起來。\n",
    "\n",
    "5. 重複迭代：重複步驟 2 到 4，每次迭代都會進一步修正預測誤差，並且添加新的弱學習器。\n",
    "\n",
    "6. 合併模型：最終將所有弱學習器的預測結果結合起來，形成整體的預測模型。\n",
    "\n",
    "### 備註\n",
    "第三步-訓練新模型, 是使用前一步得到的殘差當作新的 y, 繼續用原來的特徵去 fit model. 這樣能糾正模型的原因是因為, 如果殘差較大則模型會受的倒影響更多, 更專注於那筆資料."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[圖片來源](https://www.geeksforgeeks.org/ml-gradient-boosting/)\n",
    "\n",
    "![圖片](https://media.geeksforgeeks.org/wp-content/uploads/20200721214745/gradientboosting.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 優缺點\n",
    "\n",
    "### 優點：\n",
    "\n",
    "* 強大的預測能力： Gradient Boosting 通常在預測任務中表現出色，尤其是在處理複雜的非線性關係時。\n",
    "\n",
    "* 對噪音數據的魯棒性： 由於 Gradient Boosting 通常會專注於調整模型以捕捉訓練樣本的殘差，它對於噪音數據的魯棒性相對較高，能夠減少對噪音的敏感性。\n",
    "\n",
    "* 特徵重要性評估： Gradient Boosting 可以提供特徵的重要性評估，這有助於理解模型如何進行預測，從而進行特徵選擇和解釋模型。\n",
    "\n",
    "* 靈活性： 可以使用不同的基模型（例如決策樹）作為弱學習器，並且具有多個超參數可以調整，使其在各種情況下都能夠取得良好的效果。\n",
    "\n",
    "### 缺點：\n",
    "\n",
    "* 複雜性和計算成本： Gradient Boosting 涉及多個迭代和弱學習器的組合，因此它可能比較複雜且需要更多的計算成本，尤其是在超參數調整和訓練大型數據集時。\n",
    "\n",
    "* 容易過擬合： 如果過度迭代或使用較大的學習率，Gradient Boosting 容易過度擬合訓練數據，這可能導致在測試數據上表現不佳。\n",
    "\n",
    "* 超參數調整： Gradient Boosting 有多個超參數，需要仔細調整才能達到最佳性能，這可能需要一些經驗和時間。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python\n",
    "```python\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "...\n",
    "adaboost_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "...\n",
    "```\n",
    "\n",
    "### 參數解釋\n",
    "\n",
    "* n_estimators: 弱學習器的數量，也就是要執行幾次梯度提升的步驟。通常越多越好，但過多也可能導致過擬合。\n",
    "\n",
    "* learning_rate: 梯度提升的學習率，控制每個弱學習器的貢獻。較小的學習率會使訓練過程更穩定，但需要更多的弱學習器。\n",
    "\n",
    "* max_depth: 決策樹的最大深度。控制樹的複雜度，避免過度擬合。通常和 n_estimators 一起調整。\n",
    "\n",
    "* min_samples_split: 內部節點分割所需的最小樣本數。控制樹的增長，避免過度擬合。\n",
    "\n",
    "* subsample: 樣本的子集大小，用於每個弱學習器的訓練。較小的子集可以降低過擬合風險，但也可能降低性能。\n",
    "\n",
    "* loss: 損失函數，指定模型的優化目標。在分類問題中，通常使用 deviance（交叉熵），也可以使用 exponential。\n",
    "\n",
    "* random_state: 隨機種子，用於控制模型的隨機性。如果需要重複實驗，可以固定隨機種子。\n",
    "\n",
    "* criterion: 在每個節點上用於測量質量的函數。對於分類問題，通常使用 gini 或 entropy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost 模型的準確率: 0.94\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 生成虛擬數據，維度為4\n",
    "X, y = make_classification(n_samples=1000, n_features=4, random_state=42)\n",
    "\n",
    "# 分割數據集為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 創建 AdaBoost 分類模型\n",
    "adaboost_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# 訓練模型\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = adaboost_model.predict(X_test)\n",
    "\n",
    "# 計算準確率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"AdaBoost 模型的準確率:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
