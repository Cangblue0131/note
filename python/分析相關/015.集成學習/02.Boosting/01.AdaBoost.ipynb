{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost\n",
    "\n",
    "AdaBoost 通過專注於之前模型分類錯誤的樣本，逐步提升模型的性能。它在每一輪迭代中調整樣本權重，並根據學習器的誤差來調整模型的權重，使得在模型組合中表現較好的學習器具有較大的影響力。這種遞增的權重調整和模型組合能夠最大程度地減少模型的偏差和變異性，從而提升整體預測性能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本步驟\n",
    "\n",
    "1. 初始化權重：對每個訓練樣本賦予一個初始權重，通常均分或設為相等值。\n",
    "\n",
    "2. 訓練弱學習器：訓練一個弱學習器（通常是決策樹），使用訓練數據和初始權重。弱學習器的訓練目標是使其預測誤差最小化。\n",
    "\n",
    "3. 計算錯誤率：計算弱學習器的預測誤差，並根據誤差率調整樣本權重。被錯誤分類的樣本權重會增加，被正確分類的樣本權重會減少。\n",
    "\n",
    "4. 更新權重：計算每個樣本的新權重，以便在下一個弱學習器訓練中更關注之前分類錯誤的樣本。\n",
    "\n",
    "5. 計算弱學習器權重：基於弱學習器的誤差率計算其在最終模型中的權重。誤差率較低的弱學習器將獲得更高的權重。\n",
    "\n",
    "6. 構建強學習器：通過線性組合多個弱學習器，每個弱學習器的權重取決於其在模型中的表現。\n",
    "\n",
    "7. 預測：使用最終的強學習器對新數據進行預測。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[圖片來源](https://www.researchgate.net/figure/Illustration-of-AdaBoost-algorithm-for-creating-a-strong-classifier-based-on-multiple_fig9_288699540)\n",
    "\n",
    "![圖片](https://www.researchgate.net/profile/Zhuo-Wang-36/publication/288699540/figure/fig9/AS:668373486686246@1536364065786/Illustration-of-AdaBoost-algorithm-for-creating-a-strong-classifier-based-on-multiple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 優缺點\n",
    "\n",
    "### 優點：\n",
    "\n",
    "* 提升性能： AdaBoost 能夠將多個弱學習器組合成一個強學習器，從而提升整體預測性能。\n",
    "\n",
    "* 適用於各種任務： AdaBoost 適用於分類和回歸任務，且能夠處理二元和多類別分類問題。\n",
    "\n",
    "* 降低過擬合風險： 通過調整樣本權重，AdaBoost 降低了對噪音數據的過度依賴，減少了過擬合的風險。\n",
    "\n",
    "* 無需過多調參： AdaBoost 的主要參數是學習器數量，一般情況下不需要過多調參。\n",
    "\n",
    "* 無需特徵選擇： AdaBoost 能夠適應不同的特徵，不需要事先選擇和轉換特徵。\n",
    "\n",
    "### 缺點：\n",
    "\n",
    "* 對噪音敏感： 如果訓練數據中存在大量的噪音，AdaBoost 可能會受到影響，因為它傾向於將噪音樣本當作困難樣本來學習。\n",
    "\n",
    "* 計算成本高： AdaBoost 需要依次訓練多個弱學習器，因此在訓練過程中的計算成本相對較高。\n",
    "\n",
    "* 無法解決無法切分的問題： 如果基於弱學習器的特性，無法有效切分某些複雜的數據分布，則 AdaBoost 的性能可能受到限制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python\n",
    "```python\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "...\n",
    "# 創建 AdaBoost 分類模型\n",
    "adaboost_model = AdaBoostClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# 訓練模型\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "...\n",
    "```\n",
    "\n",
    "參數解釋\n",
    "\n",
    "* estimator：基模型，預設為 DecisionTreeClassifier(max_depth=1)，也可以使用其他分類模型。基模型是弱學習器，通常是一個簡單的分類器。\n",
    "\n",
    "* n_estimators：弱學習器的數量，預設為50。更多的弱學習器可能會提高模型性能，但也可能增加過擬合風險。\n",
    "\n",
    "* learning_rate：學習率，預設為1.0。用於控制每個弱學習器的權重，較小的學習率可能會使模型更穩定，但可能需要更多的弱學習器。\n",
    "\n",
    "* algorithm：訓練算法，預設為'SAMME.R'。有兩個選項，'SAMME' 和 'SAMME.R'，其中 'SAMME.R' 收斂速度更快。\n",
    "\n",
    "* random_state：隨機種子，確保結果可重現。\n",
    "\n",
    "* n_jobs：並行處理的作業數，預設為1。設置為-1表示使用所有可用的CPU核心。\n",
    "\n",
    "### algorithm\n",
    "\n",
    "* 'SAMME'：\n",
    "\n",
    "    這是基於多類別版本的 AdaBoost 演算法。它使用樣本的真實標籤和模型預測的標籤之間的差異來調整每個弱學習器的權重。這種方法適用於二元分類和多類別分類問題。\n",
    "\n",
    "* 'SAMME.R'：\n",
    "\n",
    "    這是 'Real' 版本的 'SAMME' 演算法。不同於 'SAMME'，'SAMME.R' 會將每個弱學習器的預測轉化為實數值，並基於加權投票的方式來進行分類。此算法在某些情況下可能比 'SAMME' 更快地達到收斂。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost 模型的準確率: 0.875\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 生成虛擬數據，維度為4\n",
    "X, y = make_classification(n_samples=1000, n_features=4, random_state=42)\n",
    "\n",
    "# 分割數據集為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 創造模型\n",
    "log_model = LogisticRegression()\n",
    "\n",
    "# 創建 AdaBoost 分類模型\n",
    "adaboost_model = AdaBoostClassifier(estimator = log_model, n_estimators=200, learning_rate = 0.01, random_state=42)\n",
    "\n",
    "# 訓練模型\n",
    "adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "# 預測測試集\n",
    "y_pred = adaboost_model.predict(X_test)\n",
    "\n",
    "# 計算準確率\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"AdaBoost 模型的準確率:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
