{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted Averaging\n",
    "\n",
    "在 Stacking 的方法中，Weighted Averaging 是一種將多個基本模型的預測結果進行加權平均的技術。與 Simple Averaging 不同，Weighted Averaging 考慮到每個基本模型的重要性，並給予不同的模型不同的權重，以便更有效地結合它們的預測。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 執行步驟\n",
    "\n",
    "1. 選擇基本模型：選擇要使用的基本模型，並對它們進行訓練。\n",
    "\n",
    "2. 得到基本模型的預測結果：對測試數據集使用每個基本模型進行預測，得到一系列的預測結果。\n",
    "\n",
    "3. 決定權重：為每個基本模型指定一個權重，這個權重可以根據模型的性能或其他因素來決定。權重可以是任意數值，但通常會總和為1，以確保加權平均的結果仍然在預測目標的範圍內。\n",
    "\n",
    "4. 加權平均：將每個基本模型的預測結果進行加權平均，按照所分配的權重進行加權，從而得到最終的集成模型預測結果。\n",
    "\n",
    "5. 評估：使用集成模型的預測結果進行評估，例如計算準確度、AUC 或其他適當的指標。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 優缺點\n",
    "\n",
    "### 優點：\n",
    "\n",
    "* 考慮模型重要性：Weighted Averaging 可以根據基本模型的性能或其他因素，賦予不同模型不同的權重，以更好地反映它們的重要性，提高集成模型的整體性能。\n",
    "\n",
    "* 適應性：透過調整權重，可以適應不同模型在不同任務中的表現。在特定情況下，一些模型可能更適合進行預測，而另一些模型則可能更適合用於其他方面。\n",
    "\n",
    "* 線性結合：Weighted Averaging 以線性結合的方式將基本模型的預測結果結合在一起，這可以有效地捕捉多個模型的不同特點，進而提升整體預測能力。\n",
    "\n",
    "### 缺點：\n",
    "\n",
    "* 需要權重調整：權重的選擇可能需要一定的經驗和嘗試。不同的權重組合可能會對結果產生不同的影響，因此需要進行調整和實驗。\n",
    "\n",
    "* 需要基本模型的表現信息：Weighted Averaging 需要對基本模型的性能進行評估，以確定如何分配權重。如果對基本模型的性能了解不足，可能難以確定適當的權重。\n",
    "\n",
    "* 不保證最佳組合：雖然加權平均可以結合多個模型，但不能保證一定能夠獲得最佳組合。有時候，最佳組合可能需要更複雜的組合技巧或其他集成方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 生成模擬數據\n",
    "X, y = make_classification(n_samples=1000, n_features=5, random_state=42)\n",
    "\n",
    "# 分割數據集為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 創建三個基本模型\n",
    "model1 = RandomForestClassifier(random_state=42)\n",
    "model2 = GradientBoostingClassifier(random_state=42)\n",
    "model3 = LogisticRegression(random_state=42)\n",
    "\n",
    "# 訓練基本模型\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)\n",
    "model3.fit(X_train, y_train)\n",
    "\n",
    "# 得到基本模型的預測結果\n",
    "pred1 = model1.predict(X_test)\n",
    "pred2 = model2.predict(X_test)\n",
    "pred3 = model3.predict(X_test)\n",
    "\n",
    "# 指定權重\n",
    "weights = [0.3, 0.4, 0.3]\n",
    "\n",
    "# 加權平均\n",
    "ensemble_pred = np.round(weights[0] * pred1 + weights[1] * pred2 + weights[2] * pred3)\n",
    "\n",
    "# 計算集成模型的準確度\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_pred)\n",
    "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
