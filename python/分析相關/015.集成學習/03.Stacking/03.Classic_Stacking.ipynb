{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic Stacking\n",
    "\n",
    "\"Classic Stacking\" 是一種 Ensemble Learning 方法，旨在提高機器學習模型的預測性能。該方法使用一個組合的方式，將多個基本模型的預測結果結合起來，從而產生一個更強大的預測模型。(簡單來說就是基本的 stacking)\n",
    "\n",
    "Classic Stacking 的主要思想在於結合多種模型，充分利用每個模型的優勢，以提高整體的預測能力。然而，Classic Stacking 也需要注意避免過度擬合，並且在設計時需要更多的調參和實驗。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 執行步驟\n",
    "\n",
    "1. 資料分割： 將訓練資料分為多個不重疊的部分，通常使用交叉驗證來實現。\n",
    "\n",
    "2. Base Models 訓練： 對每個部分的訓練資料，使用多種不同的基本模型（如決策樹、隨機森林、支持向量機等）進行訓練。\n",
    "\n",
    "3. Base Models 預測： 使用訓練好的基本模型來預測測試資料。\n",
    "\n",
    "4. Meta Model 訓練： 將每個基本模型的預測結果作為新的特徵，並使用真實的目標變數（原始訓練資料的目標值）作為標籤，訓練一個高階模型，稱為 Meta Model 或 Stacking Model。\n",
    "\n",
    "5. 預測： 使用 Meta Model 對測試資料進行預測。這個步驟將涉及使用每個基本模型的預測結果作為輸入，然後通過 Meta Model 進行最終預測。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 優缺點\n",
    "\n",
    "### 優點：\n",
    "\n",
    "* 提高預測性能：通過結合多種模型的優勢，可以獲得更好的預測結果。\n",
    "* 增強泛化能力：減少個別模型的局限性，提高模型的泛化能力。\n",
    "\n",
    "### 缺點：\n",
    "\n",
    "* 複雜性：Classic Stacking 需要管理多個基本模型和 Meta Model，訓練和調參需要額外的工作。\n",
    "* 資源需求：需要更多的計算資源和時間，特別是當基本模型較多時。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 0.885\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 生成隨機數據\n",
    "X, y = make_classification(n_samples=1000, n_features=5, random_state=42)\n",
    "\n",
    "# 分割訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 創建基本模型\n",
    "base_model1 = DecisionTreeClassifier(random_state=42)\n",
    "base_model2 = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# 訓練基本模型\n",
    "base_model1.fit(X_train, y_train)\n",
    "base_model2.fit(X_train, y_train)\n",
    "\n",
    "# 使用基本模型進行預測\n",
    "pred1 = base_model1.predict(X_test)\n",
    "pred2 = base_model2.predict(X_test)\n",
    "\n",
    "# 創建 Meta Model\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "# 使用基本模型的預測結果作為特徵，訓練 Meta Model\n",
    "meta_features = np.column_stack((pred1, pred2))\n",
    "meta_model.fit(meta_features, y_test)\n",
    "\n",
    "# 使用 Meta Model 進行最終預測\n",
    "meta_pred = meta_model.predict(meta_features)\n",
    "\n",
    "# 計算最終預測的準確性\n",
    "accuracy = accuracy_score(y_test, meta_pred)\n",
    "print(\"Final Accuracy:\", accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
