{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Averaging \n",
    "\n",
    "Stacking的Simple Averaging是一種簡單且直觀的集成方法，它的思想是將多個基本模型的預測結果進行平均來得到最終的預測結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟\n",
    "\n",
    "1. 基本模型訓練：訓練多個不同的基本模型，每個模型都使用相同的訓練數據。\n",
    "\n",
    "2. 基本模型預測：對測試數據使用每個基本模型進行預測，得到一系列不同的預測結果。\n",
    "\n",
    "3. 預測結果平均：將各個基本模型的預測結果進行簡單平均，得到最終的預測結果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 優缺點\n",
    "\n",
    "### Stacking with Simple Averaging 的優點：\n",
    "\n",
    "* 簡單直觀：這是一種簡單且容易實現的方法，不需要太多複雜的技術。\n",
    "\n",
    "* 平滑預測：平均化不同模型的預測可以減少單一模型的預測變異，有助於更穩定的預測。\n",
    "\n",
    "* 適應不同模型：可以結合多個不同性能和特點的模型，從而獲得更好的整體預測性能。\n",
    "\n",
    "### Stacking with Simple Averaging 的缺點：\n",
    "\n",
    "* 忽略模型關聯性：這種簡單的平均方法忽略了模型之間可能存在的複雜關聯性，無法最大程度地捕捉不同模型的優點。\n",
    "\n",
    "* 相同權重平均：每個模型的預測在平均時都被賦予相同的權重，忽略了不同模型可能在不同情況下的表現差異。\n",
    "\n",
    "* 可能過於保守：由於所有模型的預測都被平均，可能會導致整體預測的保守性，無法充分利用某些模型的高質量預測。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 生成模擬數據\n",
    "X, y = make_classification(n_samples=1000, n_features=5, random_state=42)\n",
    "\n",
    "# 分割數據集為訓練集和測試集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 創建五個基本模型\n",
    "model1 = RandomForestClassifier(random_state=42)\n",
    "model2 = GradientBoostingClassifier(random_state=42)\n",
    "model3 = LogisticRegression(random_state=42)\n",
    "model4 = RandomForestClassifier(max_depth=3, random_state=42)\n",
    "model5 = GradientBoostingClassifier(max_depth=3, random_state=42)\n",
    "\n",
    "# 訓練基本模型\n",
    "model1.fit(X_train, y_train)\n",
    "model2.fit(X_train, y_train)\n",
    "model3.fit(X_train, y_train)\n",
    "model4.fit(X_train, y_train)\n",
    "model5.fit(X_train, y_train)\n",
    "\n",
    "# 得到基本模型的預測結果\n",
    "pred1 = model1.predict(X_test)\n",
    "pred2 = model2.predict(X_test)\n",
    "pred3 = model3.predict(X_test)\n",
    "pred4 = model4.predict(X_test)\n",
    "pred5 = model5.predict(X_test)\n",
    "\n",
    "# 將基本模型的預測結果進行平均\n",
    "ensemble_pred = np.round((pred1 + pred2 + pred3 + pred4 + pred5) / 5)\n",
    "\n",
    "# 計算集成模型的準確度\n",
    "ensemble_accuracy = accuracy_score(y_test, ensemble_pred)\n",
    "print(\"Ensemble Accuracy:\", ensemble_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
