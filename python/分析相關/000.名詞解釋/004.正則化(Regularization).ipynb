{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正則化(Regularization)\n",
    "\n",
    "正則化是機器學習和統計中的一種技術，用於控制模型的複雜度，以<font size = 4 color = orange>避免過度擬合（過度訓練）和提升模型的泛化能力</font>, 但同時可能會導致模型在訓練數據上的性能下降。\n",
    "\n",
    "正則化的方法是<font size = 4 color = orange>在模型的損失函數中加入額外的懲罰項</font>, 這些項通常是模型參數的絕對值或平方，根據不同的方法而定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 常見的正則化\n",
    "\n",
    "* L1 正則化（Lasso 正則化）：通過將模型參數的絕對值添加到損失函數中，鼓勵某些特徵的係數變成零，實現特徵選擇，適用於稀疏特徵的情況。\n",
    "\n",
    "    Loss = Original Loss + $\\lambda\\sum^{n}_{i+1}|w_i|$\n",
    "\n",
    "* L2 正則化（Ridge 正則化）：通過將模型參數的平方和添加到損失函數中，使係數趨近於零但不會等於零，有效地減少模型參數的大小，有助於解決共線性問題。\n",
    "\n",
    "    Loss = Original Loss + $\\lambda\\sum^{n}_{i+1}w_i^2$\n",
    "\n",
    "* Elastic Net 正則化：結合了 L1 和 L2 正則化，同時考慮特徵選擇和參數收縮的效果。\n",
    "\n",
    "    Loss = Original Loss + $\\lambda(\\alpha\\sum^n_{i=1}|w_i| + (1-\\alpha)\\sum^n_{i=1}w_i^2) $\n",
    "\n",
    "其中\n",
    "* $\\lambda$ 是正則化參數, 越大懲罰力度越大, <font size = 4 color = orange>並非越大或越小越好</font>\n",
    "* $w_i$ 是模型第i個參數值\n",
    "* $\\alpha$ 是 Elastic Net 中 Lasso 和 Ridge 的比例."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
